{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ILSVRC2012 Animal Subset Hierarchical Classification (Tensorflow 2.2.0)\n",
    "\n",
    "    Author: Lukas Friedrichsen (friedrichsen.luk@googlemail.com)\n",
    "    License: Apache License, Version 2.0\n",
    "\n",
    "Description: In this notebook, different experiments are conducted on various scenarios from the field of image recognition to assess the viability of modularization as a technique to counteract specific inherent shortcomings of Neural Networks. In the first experiment, the performance of a hierarchically composed network is evaluated and compared to a monolithic benchmark model similar to the first experiment on the CIFAR100 dataset. However, instead of the latter, the disproportionally more complex ILSVRC2012 animal subset is used as the reference dataset. The goal of this experiment is to assess the general applicability of the proposed approach, i. e. to evaluate whether the results on the CIFAR100 dataset can be qualitatively reproduced on a completely different dataset with a different reference network architecture. Furthermore, since the ImageNet animal subset infers a sufficient number of hierarchical layers, we also examine the propagation of modularization errors in the composed network in a second experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "1. [Imports](#imports)\n",
    "2. [Configuration](#config)\n",
    "3. [Loading the dataset](#load)\n",
    "  1. [ILSVRC2012 dataset (complete)](#load_ilsvrc2012_complete)\n",
    "  2. [ILSVRC2012 dataset (animal subset)](#load_ilsvrc2012_animal_subset)\n",
    "4. [Mapping synset relationships](#synset_mapping)\n",
    "5. [Processing and augmentation](#processing_augmentation)\n",
    "6. [Model template (VGG)](#template)\n",
    "7. [Composed Network (CompNet)](#compnet)\n",
    "  1. [Model](#compnet_model)\n",
    "  2. [Training](#compnet_train)\n",
    "  3. [Testing](#compnet_test)\n",
    "8. [Benchmark: VGG-19 (Simonyan et. al, 2015)](#benchmark)\n",
    "  1. [Model](#benchmark_model)\n",
    "  2. [Training](#benchmark_train)\n",
    "  3. [Testing](#benchmark_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Imports\n",
    "<a id ='imports'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "# Matplotlib configuration\n",
    "\n",
    "# General settings\n",
    "mpl.rcParams['axes.grid'] = True\n",
    "mpl.rcParams['grid.alpha'] = 0.5\n",
    "mpl.rcParams['grid.linestyle'] = '--'\n",
    "mpl.rcParams['legend.framealpha'] = 1.0\n",
    "mpl.rcParams['savefig.bbox'] = 'tight'\n",
    "\n",
    "# Font sizes\n",
    "mpl.rcParams['axes.labelsize'] = 15\n",
    "mpl.rcParams['axes.titlesize'] = 15\n",
    "mpl.rcParams['figure.titlesize'] = 20\n",
    "mpl.rcParams['legend.fontsize'] = 15\n",
    "mpl.rcParams['xtick.labelsize'] = 15 \n",
    "mpl.rcParams['ytick.labelsize'] = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "print('Tensorflow: v{}'.format(tf.__version__))\n",
    "print('Tensorflow Datasets: v{}'.format(tfds.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the storage resp. lookup directory for the WordNet corpus\n",
    "# import nltk\n",
    "# nltk.data.path = ['${HOME}/.pyenv/versions/3.6.9/share/nltk_data/']\n",
    "\n",
    "# Download the WordNet corpus and extract it to the specified directory (make sure the directory\n",
    "# exists prior to execution)\n",
    "# nltk.download('wordnet', download_dir=nltk.data.path[0])\n",
    "\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducability\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Configuration\n",
    "<a id ='config'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and storage locations for Tensorflow Datasets\n",
    "TFDS_DATA_DIR = '/Volumes/Data/tensorflow_datasets/'\n",
    "TFDS_DOWNLOAD_DIR = '/Volumes/Data/tensorflow_datasets/downloads/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storage locations for model checkpoints and training logs\n",
    "CKPT_DIR = '.model_checkpoints/ilsvrc2012/'\n",
    "LOG_DIR = 'logs/ilsvrc2012/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storage location for data from experiments\n",
    "RESULTS_DIR = 'results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset specific configuration\n",
    "\n",
    "# Storage locations for data from experiments on the composed resp. benchmark network\n",
    "ILSVRC2012_RESULTS_DIR_COMPNET = RESULTS_DIR + 'ilsvrc2012/compnet/'\n",
    "ILSVRC2012_RESULTS_DIR_BENCHMARK = RESULTS_DIR + 'ilsvrc2012/benchmark/'\n",
    "\n",
    "# Storage location of the ILSVRC2012 animal subset\n",
    "ILSVRC2012_ANIMAL_SUBSET_TRAIN_FILE = TFDS_DATA_DIR + 'imagenet2012/animal_subset/train.tfrecord'\n",
    "ILSVRC2012_ANIMAL_SUBSET_VAL_FILE = TFDS_DATA_DIR + 'imagenet2012/animal_subset/val.tfrecord'\n",
    "ILSVRC2012_ANIMAL_SUBSET_TEST_FILE = TFDS_DATA_DIR + 'imagenet2012/animal_subset/test.tfrecord'\n",
    "\n",
    "# File containing the WordNet synset IDs corresponding to the numeric labels of the ILSVRC2012 dataset\n",
    "# Label 'i' in the dataset corresponds to the i-th entry of the file\n",
    "ILSVRC2012_LABELS_TO_WNIDS_FILE = TFDS_DATA_DIR + 'imagenet2012/2.0.1/label.labels.txt'\n",
    "\n",
    "# Keys of the dataset fields containing images and labels\n",
    "ILSVRC2012_IMG_KEY = 'image'\n",
    "ILSVRC2012_LABEL_KEY = 'label'\n",
    "\n",
    "# Synset level of the different taxonomic label categories (indicating the hierarchical relation between\n",
    "# the different categories)\n",
    "ILSVRC2012_PHYLUM_LABEL_LEVEL = 0\n",
    "ILSVRC2012_CLASS_LABEL_LEVEL = 1\n",
    "ILSVRC2012_ORDER_LABEL_LEVEL = 2\n",
    "ILSVRC2012_SPECIES_LABEL_LEVEL = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing configuration\n",
    "\n",
    "# Quality of the JPEG compression (from 0 to 100 with higher numbers indicating better quality at the\n",
    "# cost of higher processing time and a larger storage footpring)\n",
    "JPEG_COMP_QUALITY = 80\n",
    "\n",
    "# Desired size the smallest side of the images\n",
    "MIN_IMG_SIZE = 256\n",
    "\n",
    "# Cropping dimensions\n",
    "CROP_SIZE_H = 224\n",
    "CROP_SIZE_W = 224\n",
    "\n",
    "# RGB channel value range\n",
    "RGB_MIN_VAL = 0\n",
    "RGB_MAX_VAL = 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Loading the dataset\n",
    "<a id='load'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ILSVRC2012 dataset (complete)\n",
    "<a id='load_ilsvrc2012_complete'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ilsvrc2012_train_raw, ilsvrc2012_val_raw, ilsvrc2012_test_raw], ilsvrc2012_info = tfds.load('imagenet2012',\n",
    "                                                                                             split=[tfds.Split.TRAIN.subsplit(tfds.percent[:80]),\n",
    "                                                                                                    tfds.Split.TRAIN.subsplit(tfds.percent[-20:]),\n",
    "                                                                                                    tfds.Split.VALIDATION],\n",
    "                                                                                             data_dir=TFDS_DATA_DIR,\n",
    "                                                                                             download_and_prepare_kwargs={'download_dir': TFDS_DOWNLOAD_DIR},\n",
    "                                                                                             with_info=True)\n",
    "print(ilsvrc2012_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ILSVRC2012 dataset (animal subset)\n",
    "<a id='load_ilsvrc2012_animal_subset'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the animal subset from the (raw) ILSVRC2012 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ilsvrc2012_serialize_record(image, label):\n",
    "    '''Serializes a given record in the form (`image`, `label`) utilizing tf.train.Example\n",
    "    \n",
    "    Args:\n",
    "        image: 3-D image `Tensor`\n",
    "        label (str): Label associated to `img`\n",
    "    \n",
    "    Returns:\n",
    "        serialized_record: Tensor containing the serialized record in string format \n",
    "    '''\n",
    "    \n",
    "    # JPEG-encode the image to reduce its storage footprint\n",
    "    image = tf.io.encode_jpeg(image, quality=JPEG_COMP_QUALITY)\n",
    "\n",
    "    # Create a dictionary mapping the feature names to the respective tf.train.Example-compatible\n",
    "    # data type\n",
    "    record = {\n",
    "        ILSVRC2012_IMG_KEY: tf.train.Feature(\n",
    "            bytes_list=tf.train.BytesList(value=[image.numpy()])),\n",
    "        ILSVRC2012_LABEL_KEY: tf.train.Feature(\n",
    "            bytes_list=tf.train.BytesList(value=[label.numpy()]))\n",
    "    }\n",
    "    \n",
    "    return tf.train.Example(features=tf.train.Features(feature=record)).SerializeToString()\n",
    "\n",
    "# TensorFlow wrapper to be able to apply this function to placeholder object, thus being able to\n",
    "# employ it in `tf.data.Dataset.map` functions\n",
    "def tf_ilsvrc2012_serialize_record(image, label):\n",
    "    return tf.py_function(ilsvrc2012_serialize_record, inp=(image, label), Tout=tf.dtypes.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and prepare the animal subset from the (raw) ILSVRC2012 dataset\n",
    "# Annotation: This cell needs to be run only once; afterwards, the animal subset can be loaded from\n",
    "# storage as demonstrated in the subsequent cell. Furthermore, the extraction and preparation uses\n",
    "# functions from the 'Mapping synset relationships' and 'Processing and Augmentation' sections. Thus\n",
    "# these need to be run before executing this cell. Nevertheless, we do think that it makes sense to\n",
    "# place the latter at this point rather than later in the course for reasons of context.\n",
    "\n",
    "datasets = [ilsvrc2012_train_raw, ilsvrc2012_val_raw, ilsvrc2012_test_raw]\n",
    "file_paths = [ILSVRC2012_ANIMAL_SUBSET_TRAIN_FILE,\n",
    "              ILSVRC2012_ANIMAL_SUBSET_VAL_FILE,\n",
    "              ILSVRC2012_ANIMAL_SUBSET_TEST_FILE]\n",
    "\n",
    "# List of all synsets to be included in the ILSVRC2012 animal subset\n",
    "animal_synsets = ILSVRC2012_SYNSET_MAP.get_all_synsets_of_level(ILSVRC2012_SPECIES_LABEL_LEVEL)\n",
    "\n",
    "for dataset, file_path in zip(datasets, file_paths):\n",
    "    # Manually filter out ambiguous concepts `cardigan` and `crane`\n",
    "    dataset = dataset.filter(\n",
    "        lambda record: not tf.math.reduce_any(\n",
    "            [tf.math.equal(record[ILSVRC2012_LABEL_KEY], label) for label in [474, 517]]))\n",
    "    \n",
    "    # Decode numeric labels\n",
    "    dataset = dataset.map(\n",
    "        lambda record: {ILSVRC2012_IMG_KEY: record[ILSVRC2012_IMG_KEY],\n",
    "                        ILSVRC2012_LABEL_KEY: tf_ilsvrc2012_decode_native(record[ILSVRC2012_LABEL_KEY], use_wnid=False)},\n",
    "        num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    # Filter out all entries that do not belong to the animal subset (as defined in `ILSVRC2012_SYNSET_MAP`)\n",
    "    dataset = dataset.filter(\n",
    "        lambda record: tf.math.reduce_any(\n",
    "            [tf.math.equal(record[ILSVRC2012_LABEL_KEY], synset) for synset in animal_synsets]))\n",
    "    \n",
    "    # Resize images so that the smallest side is `MIN_IMG_SIZE` pixels afterwards\n",
    "    dataset = dataset.map(\n",
    "        lambda record: {ILSVRC2012_IMG_KEY: aspect_preserving_resize(record[ILSVRC2012_IMG_KEY], MIN_IMG_SIZE),\n",
    "                        ILSVRC2012_LABEL_KEY: record[ILSVRC2012_LABEL_KEY]},\n",
    "        num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    # Serialize the filtered and processed records\n",
    "    dataset = dataset.map(\n",
    "        lambda record: tf_ilsvrc2012_serialize_record(record[ILSVRC2012_IMG_KEY], record[ILSVRC2012_LABEL_KEY]),\n",
    "        num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    # Write the serialized records to their respecitve storage location\n",
    "    writer = tf.data.experimental.TFRecordWriter(file_path, compression_type='GZIP')\n",
    "    writer.write(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the ILSVRC2012 animal subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and parse the animal subset from the (raw) ILSVRC2012 dataset\n",
    "# Annotation: Subsequently, the usage of the ILSVRC2012 animal subset is assumed, not the raw dataset.\n",
    "\n",
    "# Template of the structure of the individual records to apply when parsing the serialized dataset\n",
    "record_template = {\n",
    "    ILSVRC2012_IMG_KEY: tf.io.FixedLenFeature([], tf.dtypes.string, default_value=''),\n",
    "    ILSVRC2012_LABEL_KEY: tf.io.FixedLenFeature([], tf.dtypes.string, default_value='')\n",
    "}\n",
    "\n",
    "datasets = []\n",
    "file_paths = [ILSVRC2012_ANIMAL_SUBSET_TRAIN_FILE,\n",
    "              ILSVRC2012_ANIMAL_SUBSET_VAL_FILE,\n",
    "              ILSVRC2012_ANIMAL_SUBSET_TEST_FILE]\n",
    "\n",
    "for file_path in file_paths:\n",
    "    dataset = tf.data.TFRecordDataset(file_path, compression_type='GZIP')\n",
    "    \n",
    "    # Parse the serialized `tf.train.Example` protos\n",
    "    dataset = dataset.map(\n",
    "        lambda record: tf.io.parse_single_example(record, record_template),\n",
    "        num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    # JPEG-decode the images\n",
    "    dataset = dataset.map(\n",
    "        lambda record: {ILSVRC2012_IMG_KEY: tf.io.decode_jpeg(record[ILSVRC2012_IMG_KEY]),\n",
    "                        ILSVRC2012_LABEL_KEY: record[ILSVRC2012_LABEL_KEY]},\n",
    "        num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    datasets.append(dataset)\n",
    "    \n",
    "[ilsvrc2012_train_raw, ilsvrc2012_val_raw, ilsvrc2012_test_raw] = datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a sample image to make sure loading worked correctly\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(20, 5))\n",
    "titles = ['Train', 'Validation', 'Test']\n",
    "\n",
    "for idx, dataset in enumerate([ilsvrc2012_train_raw, ilsvrc2012_val_raw, ilsvrc2012_test_raw]):\n",
    "    for record in dataset.take(1):\n",
    "        ax[idx].imshow(record[ILSVRC2012_IMG_KEY])\n",
    "        ax[idx].set_title(titles[idx])\n",
    "        ax[idx].axis('off')\n",
    "    \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the distribution of the train, validation and test dataset to validate, that the former is\n",
    "# representative for the latter two (requires the initalization of `ILSVRC2012_SYNSET_MAP` prior to\n",
    "# execution (cf. below))\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(20, 5))\n",
    "titles = ['Train', 'Validation', 'Test']\n",
    "\n",
    "for idx, dataset in enumerate([ilsvrc2012_train_raw, ilsvrc2012_val_raw, ilsvrc2012_test_raw]):\n",
    "    # Get the maximum label (called 'label depth' in Tensorflow)\n",
    "    label_depth = ILSVRC2012_NUM_LABELS_SPECIES_LAYER\n",
    "    \n",
    "    # Initialize the label distribution\n",
    "    dist = [0] * label_depth\n",
    "    \n",
    "    # Get the label distribution for the current dataset\n",
    "    for record in dataset:\n",
    "        dist[ilsvrc2012_encode(decode_string(record['label']))[0]] += 1\n",
    "        \n",
    "    # Normalize the distribution\n",
    "    dist = list(map(lambda entry: entry / sum(dist), dist)) \n",
    "                \n",
    "    # Plot the distribution\n",
    "    ax[idx].bar(range(0, len(dist)), dist, width=1)\n",
    "    ax[idx].set_title(titles[idx])\n",
    "    ax[idx].set_ylim([0, 0.005])\n",
    "    ax[idx].set_xlabel('Labels')\n",
    "    ax[idx].set_ylabel('Share')\n",
    "    \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Mapping synset relationships\n",
    "<a id='synset_mapping'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we create a mapping between hyper- and hyponyms (i.e. coarse and fine labels) in analogy to the wordnet corpus underlying ImageNet to be able to model the relations between the different hierarchy levels of labels and as a basis for the structure of the composed network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotation: We'll eventually outsource this class into a dedicated module, thus we're including\n",
    "# necessary imports, etc. here instead of putting them at the top of the notebook together with\n",
    "# the rest to keep all ressources in one place.\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "class synset_map(object):\n",
    "    '''Representational model for hierarchical syntactical structures\n",
    "    \n",
    "    This class implements a representational model for (injective) hierarchical syntactical structures.\n",
    "    It provides the necessary functionalities to create a mapping between multilayered hyper- and\n",
    "    hyponym compositions as well as to trace the inherent relations as well as to measure the semantic\n",
    "    distance between different synsets.\n",
    "    \n",
    "    Args:\n",
    "        synset_map (optional): Representational model for a hierarchical syntactical structure (e.g.\n",
    "            manually constructed; takes highest priority if provided together with `dataset` and\n",
    "            `keys`)\n",
    "        dataset (optional): Dataset-like structure that can be accessed via `keys`and that contains\n",
    "            the hyper- and hyponyms whose relation is to be mapped (assuming an unambiguous, injective\n",
    "            structure of synsets)\n",
    "        keys (optional): List of keys that can be used to access the fields of `dataset` that contain\n",
    "            the synset specifiers\n",
    "    \n",
    "    Attributes:\n",
    "        synset_map (dict): Nested structure of dicts that serves to store the hierarchical relationships\n",
    "            between the different synsets\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, synset_map=None, dataset=None, keys=None):\n",
    "        if synset_map is not None:\n",
    "            self.synset_map = synset_map\n",
    "        elif (dataset is not None) and (keys is not None):\n",
    "            self.synset_map_from_dataset(dataset, keys)\n",
    "        else:\n",
    "            self.synset_map = {}\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def synset_map(self):\n",
    "        return deepcopy(self._synset_map)\n",
    "    \n",
    "    \n",
    "    @synset_map.setter\n",
    "    def synset_map(self, synset_map):\n",
    "        elements = [synset_map]\n",
    "        for element in elements:\n",
    "            if not isinstance(element, dict):\n",
    "                raise TypeError(\n",
    "                    'All entries of `synset_map` have to be of type `dict`.\\n'\n",
    "                )\n",
    "\n",
    "            if element:\n",
    "                for value in element.values():\n",
    "                    elements.append(value)\n",
    "        \n",
    "        self._synset_map = synset_map\n",
    "        \n",
    "        self.construct_hyponym_map()\n",
    "        self.construct_hypernym_map()\n",
    "        \n",
    "    \n",
    "    def construct_hyponym_map(self):\n",
    "        '''Constructs a dictionary containing the hyponyms for every synset in `synset_map`\n",
    "        \n",
    "        Constructs a dictionary containing the hyponyms for every synset in `synset_map`. This\n",
    "        function is called exactly once every time `synset_map` is set, thus reducing the complexity\n",
    "        of subsequent lookup operations to O(1). Has to be called manually if changes to an existing\n",
    "        synset map are made.\n",
    "        \n",
    "        Raises:\n",
    "            UserWarning: If `synset_map` has not been initialized at call time\n",
    "        '''\n",
    "                \n",
    "        if not self._synset_map:\n",
    "            raise UserWarning(\n",
    "                'Please initialize `synset_map` before calling this function.\\n'\n",
    "            )\n",
    "                    \n",
    "        self._hyponyms = {}\n",
    "        \n",
    "        synsets = [self._synset_map]\n",
    "        for synset in synsets:\n",
    "            for hypernym in synset.keys():                \n",
    "                self._hyponyms[hypernym] = list(synset[hypernym].keys())\n",
    "                synsets.append(synset[hypernym])\n",
    "            \n",
    "        \n",
    "    def construct_hypernym_map(self):\n",
    "        '''Constructs a dictionary containing the complete hypernym path for every synset in `synset_map`\n",
    "        \n",
    "        Constructs a dictionary containing the complete hypernym path for every synset in `synset_map`.\n",
    "        This function is called exactly once every time `synset_map`is changed, thus reducing the\n",
    "        complexity of subsequent lookup operations to O(1). Has to be called manually if changes to\n",
    "        an existing synset map are made.\n",
    "        \n",
    "        Raises:\n",
    "            UserWarning: If `synset_map` has not been initialized at call time\n",
    "        '''\n",
    "        \n",
    "        if not self._synset_map:\n",
    "            raise UserWarning(\n",
    "                'Please initialize `synset_map` before calling this function.\\n'\n",
    "            )\n",
    "        \n",
    "        self._hypernym_paths = {}\n",
    "        \n",
    "        synsets = [self._synset_map]\n",
    "        for synset in synsets:\n",
    "            for hypernym, hyponyms in zip(synset.keys(), synset.values()):\n",
    "                hypernym_path = [hypernym]\n",
    "\n",
    "                while True:\n",
    "                    # Check if the current `hypernym` is part of the root layer (meaning it has no\n",
    "                    # further hypernyms)\n",
    "                    if hypernym in self._synset_map.keys():\n",
    "                        break\n",
    "\n",
    "                    elements = [self._synset_map]\n",
    "                    for element in elements:\n",
    "                        for key in element.keys():\n",
    "                            if hypernym in element[key].keys():\n",
    "                                hypernym = key\n",
    "                                break\n",
    "                            else:\n",
    "                                elements.append(element[key])\n",
    "\n",
    "                    hypernym_path.append(hypernym)\n",
    "\n",
    "                self._hypernym_paths[hypernym_path[0]] = hypernym_path[::-1]\n",
    "                \n",
    "                synsets.append(hyponyms)\n",
    "    \n",
    "    \n",
    "    def synset_map_from_dataset(self, dataset, keys):\n",
    "        '''Creates a mapping between hyper- and hyponyms from a given dataset\n",
    "        \n",
    "        Args:\n",
    "            dataset: Dataset-like structure that can be accessed via `keys`and that contains the\n",
    "                hyper- and hyponyms whose relation is to be mapped (assuming an unambiguous, injective\n",
    "                structure of synsets)\n",
    "            keys: List of keys that can be used to access the fields of `dataset` that contain the\n",
    "                synset specifiers\n",
    "            \n",
    "        Raises:\n",
    "            TypeError: If one of the input arguments is of the wrong type\n",
    "            ValueError: If invalid values are specified for one or more input arguments\n",
    "        '''\n",
    "        \n",
    "        if not isinstance(dataset, list):\n",
    "            raise TypeError(\n",
    "                '`dataset` is expected to be of type `list`. Is of type {}.\\n'.format(type(dataset))\n",
    "            )\n",
    "        if not dataset:\n",
    "            raise ValueError(\n",
    "                '`dataset` may not be empty.\\n'\n",
    "            )\n",
    "        if not isinstance(keys, list):\n",
    "            raise TypeError(\n",
    "                '`keys` is expected to be of type `list`. Is of type {}.\\n'.format(type(keys))\n",
    "            )\n",
    "        if not keys:\n",
    "            raise ValueError(\n",
    "                '`keys` may not be empty.\\n'\n",
    "            )\n",
    "            \n",
    "        # Determine the hierarchical relationship between the given keys (i.e. which fields in the\n",
    "        # dataset contain the highest-level synsets, which ones contain the second highest and so on)\n",
    "        \n",
    "        ordered_keys = keys\n",
    "        len_ordered_keys = len(ordered_keys)\n",
    "        if len_ordered_keys > 1:\n",
    "            # Assuming an injective structure of the syntactic relationships, determine the hierarchical\n",
    "            # relationship between two values of `keys` by simply iterate over the dataset until one\n",
    "            # of the fields differs for the same value of the field referenced by the other key,\n",
    "            # indicating that the former is a hyponym of the latter. The keys can then be sorted\n",
    "            # using e.g. Bubble Sort as is done here.\n",
    "            for i in range(len_ordered_keys):\n",
    "                for j in range(0, len_ordered_keys - i - 1):\n",
    "                    key_1 = ordered_keys[j]\n",
    "                    key_2 = ordered_keys[j + 1]\n",
    "                    \n",
    "                    val_key_1 = dataset[0][key_1]\n",
    "                    val_key_2 = dataset[0][key_2]\n",
    "                        \n",
    "                    for record in dataset:\n",
    "                        if (val_key_1 != record[key_1]) and (val_key_2 == record[key_2]):\n",
    "                            ordered_keys[j], ordered_keys[j + 1] = ordered_keys[j + 1], ordered_keys[j]\n",
    "                            break\n",
    "        \n",
    "        # Construct the mapping between hierarchically related synsets from the dataset\n",
    "        \n",
    "        synset_map = {}\n",
    "        for record in dataset:\n",
    "            synset = synset_map\n",
    "            \n",
    "            for key in ordered_keys:\n",
    "                hyponym = record[key]\n",
    "                \n",
    "                if not hyponym in synset.keys():\n",
    "                    synset[hyponym] = {}\n",
    "                    \n",
    "                synset = synset[hyponym]\n",
    "        \n",
    "        self.synset_map = synset_map\n",
    "        \n",
    "    \n",
    "    def hyponyms(self, synset):\n",
    "        '''Returns the hyponyms for a given synset\n",
    "        \n",
    "        Args:\n",
    "            synset: Key / label of the synset whose hyponyms are to be returned\n",
    "        \n",
    "        Returns:\n",
    "            hyponyms: List containing the hyponyms of the given synset (empty if `synset` is not in\n",
    "                `synset_map` or if `synset` is a leaf node)\n",
    "            \n",
    "        Raises:\n",
    "            UserWarning: If `synset_map` has not been initialized at call time\n",
    "        '''\n",
    "        \n",
    "        if not self._hyponyms:\n",
    "            raise UserWarning(\n",
    "                'Please initialize `synset_map` or call `construct_hyponym_map` before calling this function.\\n'\n",
    "            )\n",
    "            \n",
    "        hyponyms = []\n",
    "                \n",
    "        if synset in self._hyponyms.keys():\n",
    "            hyponyms = self._hyponyms[synset]\n",
    "\n",
    "        return hyponyms\n",
    "    \n",
    "    \n",
    "    def hypernym(self, synset):\n",
    "        '''Returns the hypernym for a given synset\n",
    "        \n",
    "        Args:\n",
    "            synset: Key / label of the synset whose hypernym is to be returned\n",
    "        \n",
    "        Returns:\n",
    "            hypernym: Hypernym of the given synset (`None` if `synset` is not in `synset_map` or if\n",
    "                `synset` is part of the root layer)\n",
    "            \n",
    "        Raises:\n",
    "            UserWarning: If `synset_map` has not been initialized at call time\n",
    "        '''\n",
    "        \n",
    "        if not self._hypernym_paths:\n",
    "            raise UserWarning(\n",
    "                'Please initialize `synset_map` or call `construct_hypernym_map` before calling this function.\\n'\n",
    "            )\n",
    "        \n",
    "        hypernym = None\n",
    "           \n",
    "        if synset in self._hypernym_paths.keys():\n",
    "            # Check if `synset` is part of the root layer\n",
    "            if len(self._hypernym_paths[synset]) > 1:\n",
    "                hypernym = self._hypernym_paths[synset][-2]\n",
    "        \n",
    "        return hypernym\n",
    "    \n",
    "    \n",
    "    def hypernym_path(self, synset):\n",
    "        '''Returns the hypernym path from a given synset to the root layer\n",
    "        \n",
    "        Args:\n",
    "            synset: Key / label of the synset whose hypernym path is to be returned\n",
    "        \n",
    "        Returns:\n",
    "            hypernym_path: List containing the hypernym path in descending order from the root layer\n",
    "                down to `synset` (empty if `synset` is not in `synset_map`)\n",
    "            \n",
    "        Raises:\n",
    "            UserWarning: If `synset_map` has not been initialized at call time\n",
    "        '''\n",
    "        \n",
    "        if not self._hypernym_paths:\n",
    "            raise UserWarning(\n",
    "                'Please initialize `synset_map` or call `construct_hypernym_map` before calling this function.\\n'\n",
    "            )\n",
    "            \n",
    "        hypernym_path = []\n",
    "        \n",
    "        if synset in self._hypernym_paths.keys():\n",
    "            hypernym_path = self._hypernym_paths[synset]\n",
    "                        \n",
    "        return hypernym_path\n",
    "    \n",
    "    \n",
    "    def is_a(self, hyponym, hypernym):\n",
    "        '''Checks whether a synset is a hyponym of another synset\n",
    "        \n",
    "        Args:\n",
    "            hyponym: Key / label of the hierarchically subordinate synset in question\n",
    "            hypernym: Key / label of the hierarchically superordinate synset in question\n",
    "        \n",
    "        Returns:\n",
    "            is_hyponym: Indicator whether `hyponym` is a hyponym of `hypernym`\n",
    "            \n",
    "        Raises:\n",
    "            UserWarning: If `synset_map` has not been initialized at call time\n",
    "        '''\n",
    "        \n",
    "        if not self._synset_map:\n",
    "            raise UserWarning(\n",
    "                'Please initialize `synset_map` before calling this function.\\n'\n",
    "            )\n",
    "        \n",
    "        return (hypernym in self.hypernym_path(hyponym))\n",
    "    \n",
    "    \n",
    "    def semantic_distance(self, synset_1, synset_2):\n",
    "        '''Calculates the semantic distance between two synsets in accordance to (Fergus et al., 2010)\n",
    "        \n",
    "        Args:\n",
    "            hyponym: Key / label of the first synset\n",
    "            hypernym: Key / label of the second synset\n",
    "            \n",
    "        Returns:\n",
    "            semantic_dist (float): Semantic distance between the two given synsets (0.0 if one of\n",
    "                the synsets is not in `synset_map`)\n",
    "            \n",
    "        Raises:\n",
    "            UserWarning: If `synset_map` has not been initialized at call time\n",
    "        '''\n",
    "        \n",
    "        if not self._synset_map:\n",
    "            raise UserWarning(\n",
    "                'Please initialize `synset_map` before calling this function.\\n'\n",
    "            )\n",
    "            \n",
    "        semantic_dist = 0.0\n",
    "            \n",
    "        hypernym_path_1 = self.hypernym_path(synset_1)\n",
    "        hypernym_path_2 = self.hypernym_path(synset_2)\n",
    "        \n",
    "        if hypernym_path_1 and hypernym_path_2:\n",
    "            # Semantic distance is defined by (Fergus et al., 2010) as follows:\n",
    "            # S(i, j) = intersect(path(i), path(j)) / max(length(path(i)), length(path(j)))\n",
    "            semantic_dist = len([hypernym for hypernym in hypernym_path_1 if hypernym in hypernym_path_2]) / max(len(hypernym_path_1), len(hypernym_path_2))\n",
    "        \n",
    "        return semantic_dist\n",
    "    \n",
    "    \n",
    "    def synset_level(self, synset):\n",
    "        '''Returns the level of the given synset in the syntactical structure\n",
    "        \n",
    "        Args:\n",
    "            synset: Key / label of the synset in question\n",
    "            \n",
    "        Returns:\n",
    "            level: Level of the given synset in the hierarchical structure (zero indicating root\n",
    "                level, one the first level below root level, etc.; `None` if `synset` is not in\n",
    "                `synset_map`)\n",
    "            \n",
    "        Raises:\n",
    "            UserWarning: If `synset_map` has not been initialized at call time\n",
    "        '''\n",
    "        \n",
    "        if not self._synset_map:\n",
    "            raise UserWarning(\n",
    "                'Please initialize `synset_map` before calling this function.\\n'\n",
    "            )\n",
    "        \n",
    "        hypernym_path = self.hypernym_path(synset)\n",
    "        \n",
    "        if not hypernym_path:\n",
    "            return None\n",
    "        \n",
    "        return len(hypernym_path) - 1\n",
    "    \n",
    "    \n",
    "    def get_all_synsets_of_level(self, level):\n",
    "        '''Returns all synsets of the specified level in the hierarchical syntactic structure\n",
    "        \n",
    "        Args:\n",
    "            level (int): Positive integer specifying of level of `synset_map` from which the synsets\n",
    "                are to be returned\n",
    "        \n",
    "        Returns:\n",
    "            synset: List of all synsets on the specified level in `synset_map` (empty if `level` is\n",
    "                greater than the maximum depth of `synset_map`)\n",
    "                \n",
    "        Raises:\n",
    "            TypeError: If one of the input arguments is of the wrong type\n",
    "            ValueError: If invalid values are specified for one or more input arguments\n",
    "            UserWarning: If `synset_map` has not been initialized at call time\n",
    "        '''\n",
    "        \n",
    "        if not isinstance(level, int):\n",
    "            raise TypeError(\n",
    "                '`level` is expected to be of type `int`. Is of type {}.\\n'.format(type(level))\n",
    "            )\n",
    "        if level < 0:\n",
    "            raise ValueError(\n",
    "                '`level` has to be a positive value.\\n'\n",
    "            )\n",
    "        if not self._hypernym_paths:\n",
    "            raise UserWarning(\n",
    "                'Please initialize `synset_map` or call `construct_hypernym_map` before calling this function.\\n'\n",
    "            )\n",
    "            \n",
    "        synset = []\n",
    "        \n",
    "        for hypernym_path in self._hypernym_paths.values():\n",
    "            if len(hypernym_path) - 1 >= level:\n",
    "                if hypernym_path[level] not in synset:\n",
    "                    synset.append(hypernym_path[level])\n",
    "                \n",
    "        return synset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_string(string, encoding='utf-8'):\n",
    "    '''Decodes a given string\n",
    "    \n",
    "    Args:\n",
    "        string (str): Encoded string\n",
    "        encoding (str, optional): Codec to use for decoding\n",
    "        \n",
    "    Returns:\n",
    "        decoded_string (str): Decoded string\n",
    "    '''\n",
    "        \n",
    "    # `tf.Tensor` compatibility\n",
    "    if isinstance(string, tf.Tensor):\n",
    "        string = string.numpy()\n",
    "                        \n",
    "    return string.decode(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mappings between (encoded) numeric labels and (decoded) WordNet synset IDs resp. WordNet synset\n",
    "# IDs and corresponding string literals\n",
    "ILSVRC2012_LABELS_TO_WNIDS = [decode_string(wnid) for wnid in tf.data.TextLineDataset(ILSVRC2012_LABELS_TO_WNIDS_FILE)]\n",
    "ILSVRC2012_WNIDS_TO_NAMES = [wn.synset_from_pos_and_offset(wnid[0], int(wnid[1:])).name().split('.', 1)[0] for wnid in ILSVRC2012_LABELS_TO_WNIDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotation: The decoding uses the native numeric labels of the dataset, not the relative position\n",
    "# of the respective synset in the synset mapping. To resolve the latter, use `ilsvrc2012_decode` resp.\n",
    "# `ilsvrc2012_encode`.\n",
    "\n",
    "def ilsvrc2012_decode_native(label, use_wnid=False):\n",
    "    '''Returns the literal associated with the given native encoded label\n",
    "    \n",
    "    Args:\n",
    "        label (int): ILSVRC2012 encoded (numeric) label\n",
    "        use_wnid (bool, optional): Indicator whether to return the unique WordNet ID or the name\n",
    "            (default) of the synset\n",
    "    \n",
    "    Returns:\n",
    "        decoded_label (str): String literal belonging to the given native numeric label\n",
    "    '''\n",
    "    \n",
    "    # `tf.Tensor` compatibility\n",
    "    if isinstance(label, tf.Tensor):\n",
    "        label = label.numpy()\n",
    "    \n",
    "    if use_wnid:\n",
    "        return ILSVRC2012_LABELS_TO_WNIDS[label]\n",
    "    \n",
    "    return ILSVRC2012_WNIDS_TO_NAMES[label]\n",
    "\n",
    "# TensorFlow wrapper to be able to apply this function to placeholder object, thus being able to\n",
    "# employ it in `tf.data.Dataset.map` functions\n",
    "def tf_ilsvrc2012_decode_native(label, use_wnid):\n",
    "    return tf.py_function(ilsvrc2012_decode_native, inp=(label, use_wnid), Tout=tf.dtypes.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotation: The encoding uses the native numeric labels of the dataset, not the relative position\n",
    "# of the respective synset in the synset mapping. To resolve the latter, use `ilsvrc2012_decode` resp.\n",
    "# `ilsvrc2012_encode`.\n",
    "\n",
    "def ilsvrc2012_encode_native(label):\n",
    "    '''Returns the native numeric label associated with the given string literal\n",
    "    \n",
    "    Args:\n",
    "        label (str): ILSVRC2012 decoded (string literal) label\n",
    "    \n",
    "    Returns:\n",
    "        encoded_label (int): Native numeric label belonging to the given string literal\n",
    "    '''\n",
    "    \n",
    "    # `tf.Tensor` compatibility\n",
    "    if isinstance(label, tf.Tensor):\n",
    "        label = label.numpy()\n",
    "    \n",
    "    if label in ILSVRC2012_LABELS_TO_WNIDS:\n",
    "        return ILSVRC2012_LABELS_TO_WNIDS.index(label)\n",
    "    \n",
    "    return ILSVRC2012_WNIDS_TO_NAMES.index(label)\n",
    "\n",
    "# TensorFlow wrapper to be able to apply this function to placeholder object, thus being able to\n",
    "# employ it in `tf.data.Dataset.map` functions\n",
    "def tf_ilsvrc2012_encode_native(label):\n",
    "    return tf.py_function(ilsvrc2012_encode_native, inp=(label), Tout=tf.dtypes.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotation: The encoding relative position of the respective synset in the synset mapping, not to\n",
    "# the native numeric labels of the dataset. To resolve the latter, use `ilsvrc2012_decode_native`\n",
    "# resp. `ilsvrc2012_encode_native`.\n",
    "\n",
    "def ilsvrc2012_decode(label, level=ILSVRC2012_SPECIES_LABEL_LEVEL):\n",
    "    '''Returns the literal associated with the given combination of encoded label and hierarchy level\n",
    "    \n",
    "    Args:\n",
    "        label (int): Encoded label\n",
    "        level (int): Level of the given label in the hierarchical structure\n",
    "    \n",
    "    Returns:\n",
    "        decoded_label (str): String literal belonging to the given label / level combination\n",
    "    '''\n",
    "    \n",
    "    # Cut off invalid values for `level` (has to be between `0` or `3`)\n",
    "    level = max(0, min(ILSVRC2012_SPECIES_LABEL_LEVEL, level))\n",
    "    \n",
    "    return ILSVRC2012_SYNSET_MAP.get_all_synsets_of_level(level)[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotation: The encoding relative position of the respective synset in the synset mapping, not to\n",
    "# the native numeric labels of the dataset. To resolve the latter, use `ilsvrc2012_decode_native`\n",
    "# resp. `ilsvrc2012_encode_native`.\n",
    "\n",
    "def ilsvrc2012_encode(label):\n",
    "    '''Returns the encoded (numeric) label associated with the given string literal\n",
    "    \n",
    "    Args:\n",
    "        label (str): Decoded label\n",
    "    \n",
    "    Returns:\n",
    "        encoded_label (int): Numeric label belonging to the given string literal\n",
    "        level (int): Level of the `encoded_label` in the hierarchical structure\n",
    "    '''\n",
    "    \n",
    "    level = ILSVRC2012_SYNSET_MAP.synset_level(label)\n",
    "    \n",
    "    return ILSVRC2012_SYNSET_MAP.get_all_synsets_of_level(level).index(label), level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotation: This function serves to aggregate and encapsulate all native (non-tensorized) Python\n",
    "# functionalities that require eager execution for direct data access during the preprocessing of\n",
    "# the dataset to minimize the overhead resulting from converting TensorFlow data structures to Python\n",
    "# objects and back at runtime.\n",
    "\n",
    "def ilsvrc2012_resolve_hypernym(label, level, encoded=False):\n",
    "    '''Returns the hypernym of the given (species level) label on the specified hierarchy level\n",
    "\n",
    "    Given a label on the finest supported categorical resolution (i.e. species level for the ILSVRC\n",
    "    2012 dataset) returns the related hypernym on the specified hierarchy level\n",
    "\n",
    "    Args:\n",
    "        label: Label of the synset on the finest supported categorical resolution whose hypernym is to\n",
    "            be returned in numerical or string literal format\n",
    "        level (int): Level of the given label in the hierarchical structure\n",
    "        encoded (bool, optional): Indicator whether to return the hypernym in encoded or decoded\n",
    "            format\n",
    "\n",
    "    Returns:\n",
    "        hypernym: Hypernym of the given synset on the hierarchy level specified by `level` in numerical\n",
    "            or string literal format depending on `encoded`\n",
    "    '''\n",
    "\n",
    "    # `tf.Tensor` compatibility\n",
    "    if isinstance(label, tf.Tensor):\n",
    "        label = label.numpy()\n",
    "\n",
    "    # Decode the label if it was given in encoded format\n",
    "    if not isinstance(label, str):\n",
    "        if isinstance(label, bytes):\n",
    "            # TensorFlow encodes strings as bytes by default\n",
    "            label = decode_string(label)\n",
    "        else:\n",
    "            # If `label` is given neither as string nor bytes we assume that it is given in numerical\n",
    "            # encoded format\n",
    "            label = ilsvrc2012_decode(label, ILSVRC2012_SPECIES_LABEL_LEVEL)\n",
    "\n",
    "    hypernym = ILSVRC2012_SYNSET_MAP.hypernym_path(label)[level]\n",
    "    \n",
    "    if encoded:\n",
    "        hypernym, _ = ilsvrc2012_encode(hypernym)\n",
    "\n",
    "    return hypernym\n",
    "\n",
    "# TensorFlow wrapper to be able to apply this function to placeholder object, thus being able to\n",
    "# employ it as part of the preprocessing pipeline\n",
    "def tf_ilsvrc2012_resolve_hypernym_decoded(label, level):\n",
    "    return tf.py_function(ilsvrc2012_resolve_hypernym, inp=(label, level, False), Tout=tf.dtypes.string)\n",
    "def tf_ilsvrc2012_resolve_hypernym_encoded(label, level):\n",
    "    return tf.py_function(ilsvrc2012_resolve_hypernym, inp=(label, level, True), Tout=tf.dtypes.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping between hyper- and hyponyms of the ILSVRC2012 dataset\n",
    "\n",
    "# Annotation: We tried to adhere to the underlying WordNet structure as far as possible during the\n",
    "# creation of the synset map. Adjustments to the native hierarchy were made at the following places\n",
    "# to balance out the distribution of the dataset to not unfairly put the composed approach at a\n",
    "# disadvantage in comparison to the (monolithic) benchmark architecture:\n",
    "# - Removed synsets with only one or less associated label from the total set of hyponyms of `animal`\n",
    "#       (e.g. the hyponym `tribolite` of synset `arthropod` has exactly one associated label, thus\n",
    "#       permitting no choice on the second hierarchy level in comparison to e.g. `arachnid` with 9\n",
    "#       labels and was thus removed; affected a total of 20 of 398 labels (~5%))\n",
    "# - Split up the native category `mammals` into smaller subcategories `dog`, `small_mammal`,\n",
    "#       `large_omnivore_herbivore`, `ursine`, `primatic` and `other_mammal`\n",
    "# - Aggregated native categories `coelenterate`, `echinoderm`, `mollusk` and `worm` into supercategory\n",
    "#       `molluscan`\n",
    "# - Aggregated native categories `amphibian` and `reptile` into supercategory `herpetologic`\n",
    "# These changes effect that a) each non-leaf node of the synset map has more than one direct child\n",
    "# node and does thus permit the training of a model for branch classification and b) the maximum\n",
    "# spread in the amount of data points per concept between the category with the most and the one\n",
    "# with the least associated records on any hierarchy level is limited to a factor of <15 (~5.5 on\n",
    "# the root layer, ~8.5 on the first layer and ~15 on the second layer). With regard to the latter,\n",
    "# it was additionally made sure that outlier categories with especially many data points are\n",
    "# inherently coherent in their hyponyms and can thus also be trained with fewer examples.\n",
    "\n",
    "SYNSET_MAP = {\n",
    "    'vertebrate': {\n",
    "        'bird': {\n",
    "            'aquatic_bird': {}, 'bird_of_prey': {}, 'coraciiform_bird': {}, 'gallinaceous_bird': {}, 'piciform_bird': {}, 'parrot': {}, 'passerine': {}\n",
    "        },\n",
    "        'fish': {\n",
    "            'bony_fish': {}, 'cartilaginous_fish': {}\n",
    "        },\n",
    "        'herpetologic': {\n",
    "            'crocodilian_reptile': {}, 'frog': {}, 'salamander': {}, 'saurian': {}, 'snake': {}, 'turtle': {}\n",
    "        },\n",
    "        'dog': {\n",
    "            'fox': {}, 'wild_dog': {}, 'wolf': {}, 'corgi': {}, 'poodle': {}, 'spitz': {}, 'toy_dog': {}, 'terrier': {}, 'sporting_dog': {}, 'hound': {}, 'working_dog': {}\n",
    "        },\n",
    "        'rodenticidal': {\n",
    "            'musteline_mammal': {}, 'rodent': {}, 'viverrine': {}\n",
    "        },\n",
    "        'large_omnivore_herbivore': {\n",
    "            'pachyderm': {}, 'ungulate': {}\n",
    "        },\n",
    "        'ursine': {\n",
    "            'bear': {}, 'marsupial': {}, 'procyonid': {}\n",
    "        },\n",
    "        'primatenic': {\n",
    "            'edentate': {}, 'primate': {}\n",
    "        },\n",
    "        'other_mammal': {\n",
    "            'aquatic_mammal': {}, 'feline': {}, 'lagomorph': {}, 'monotreme': {}\n",
    "        },\n",
    "    },\n",
    "    'invertebrate': {\n",
    "        'arthropod': {\n",
    "            'arachnid': {}, 'crustacean': {}, 'insect': {}\n",
    "        },\n",
    "        'molluscan': {\n",
    "            'coelenterate': {}, 'echinoderm': {}, 'mollusk': {}, 'worm': {}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Associate the species level labels of the ILSVRC2012 dataset to their respective hypernyms\n",
    "\n",
    "number_labels = len(ILSVRC2012_LABELS_TO_WNIDS)\n",
    "label_associated = [False] * number_labels\n",
    "\n",
    "# Manually filter out ambiguous concepts `cardigan` and `crane`\n",
    "label_associated[474] = True\n",
    "label_associated[517] = True\n",
    "\n",
    "synsets = [SYNSET_MAP]\n",
    "for synset in synsets:\n",
    "    for hypernym in synset.keys():\n",
    "        # Check whether the current synset is a leaf node (we don't want to associate labels to\n",
    "        # higher-level concepts like e.g. `bird` but rather only to the finest predefined resolution,\n",
    "        # i.e. e.g. `aquatic_bird`)\n",
    "        if not synset[hypernym]:\n",
    "            # Iterate over all labels of the ILSVRC2012 dataset, check which ones are hyponyms of\n",
    "            # the current synset and add those as child nodes to the synset map\n",
    "            for idx in range(number_labels):\n",
    "                wnid = ILSVRC2012_LABELS_TO_WNIDS[idx]\n",
    "                pos = wnid[0]\n",
    "                offset = int(wnid[1:])\n",
    "\n",
    "                for path in wn.synset_from_pos_and_offset(pos, offset).hypernym_paths():\n",
    "                    for variant in wn.synsets(hypernym):\n",
    "                        if variant in path:\n",
    "                            # Check whether the current label is already associated to a different\n",
    "                            # hypernym to ensure unambiguity\n",
    "                            if label_associated[idx] is False:\n",
    "                                synset[hypernym][ILSVRC2012_WNIDS_TO_NAMES[idx]] = {}\n",
    "                                label_associated[idx] = True\n",
    "                            \n",
    "        synsets.append(synset[hypernym])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a `synset_map` object from the previously prepared mapping between hyper- and hyponyms\n",
    "ILSVRC2012_SYNSET_MAP = synset_map(SYNSET_MAP)\n",
    "\n",
    "# Macros for the number of labels on the different taxonomic levels of the synset mapping\n",
    "ILSVRC2012_NUM_LABELS_PHYLUM_LAYER = len(ILSVRC2012_SYNSET_MAP.get_all_synsets_of_level(ILSVRC2012_PHYLUM_LABEL_LEVEL))\n",
    "ILSVRC2012_NUM_LABELS_CLASS_LAYER = len(ILSVRC2012_SYNSET_MAP.get_all_synsets_of_level(ILSVRC2012_CLASS_LABEL_LEVEL))\n",
    "ILSVRC2012_NUM_LABELS_ORDER_LAYER = len(ILSVRC2012_SYNSET_MAP.get_all_synsets_of_level(ILSVRC2012_ORDER_LABEL_LEVEL))\n",
    "ILSVRC2012_NUM_LABELS_SPECIES_LAYER = len(ILSVRC2012_SYNSET_MAP.get_all_synsets_of_level(ILSVRC2012_SPECIES_LABEL_LEVEL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Processing and augmentation\n",
    "<a id='processing_augmentation'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, different functions are provided for preprocessing the dataset prior to the training and inference adhering to the standard 10-crop procedure as described in (Krizhevsky et al., 2012) and (Sermanet et al., 2014) (based on https://github.com/tensorflow/models/blob/master/official/vision/image_classification/imagenet_preprocessing.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rescale the shorter side of an image to a custom size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image, height, width):\n",
    "    '''Simple, type-preserving wrapper around `tf.image.resize`\n",
    "    \n",
    "    Args:\n",
    "        image: 3-D image `Tensor`\n",
    "        height (int): Target height for the resized image\n",
    "        width (int): Target width for the resized image\n",
    "        \n",
    "    Returns:\n",
    "        resized_image: 3-D tensor containing the resized image of shape [width, height, ...]\n",
    "    '''\n",
    "\n",
    "    return tf.cast(\n",
    "        tf.image.resize(\n",
    "            image, [height, width],\n",
    "            method=tf.image.ResizeMethod.BILINEAR),\n",
    "        image.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_aspect_preserving_shape(height, width, desired_min_size):\n",
    "    '''Computes new shape with the smallest side equal to `desired_min_size`\n",
    "    \n",
    "    Computes new shape with the smallest side equal to `desired_min_size` while preserving the original\n",
    "    aspect ratio.\n",
    "    \n",
    "    Args:\n",
    "        height (int): Current height\n",
    "        width (int): Current width\n",
    "        desired_min_size (int): Desired size of the smallest side after resize\n",
    "        \n",
    "    Returns:\n",
    "        new_height (int): New height\n",
    "        new_width (int): New width\n",
    "    '''\n",
    "\n",
    "    # Convert to floats to make subsequent calculations go smoothly\n",
    "    desired_min_size = tf.cast(desired_min_size, tf.dtypes.float32)\n",
    "    height, width = tf.cast(height, tf.float32), tf.cast(width, tf.dtypes.float32)\n",
    "\n",
    "    min_dim = tf.math.minimum(height, width)\n",
    "    scale_ratio = desired_min_size / min_dim\n",
    "\n",
    "    # Convert back to ints to make heights and widths for tf.image.resize compliance\n",
    "    new_height = tf.cast(height * scale_ratio, tf.dtypes.int32)\n",
    "    new_width = tf.cast(width * scale_ratio, tf.dtypes.int32)\n",
    "\n",
    "    return new_height, new_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aspect_preserving_resize(image, desired_min_size):\n",
    "    '''Resizes images preserving the original aspect ratio\n",
    "    \n",
    "    Resizes the image with the smallest side eqaul to `desired_min_size` while preserving the original\n",
    "    aspect ratio.\n",
    "    \n",
    "    Args:\n",
    "        image: 3-D image `Tensor`\n",
    "        desired_min_size (int): Desired size of the smallest side after resize\n",
    "        \n",
    "    Returns:\n",
    "        resized_image: 3-D tensor containing the resized image\n",
    "    '''\n",
    "\n",
    "    shape = tf.shape(input=image)\n",
    "    height, width = shape[0], shape[1]\n",
    "\n",
    "    new_height, new_width = calc_aspect_preserving_shape(height, width, desired_min_size)\n",
    "\n",
    "    return resize_image(image, new_height, new_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crop out a patch of an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(image, offset_height, offset_width, target_height, target_width):\n",
    "    '''Simple, type-preserving wrapper around `tf.image.crop_to_bounding_box`\n",
    "    \n",
    "    Args:\n",
    "        image: 3-D image `Tensor`\n",
    "        offset_height (int): Vertical coordinate of the top-left corner of the crop\n",
    "        offset_width (int): Horizontal coordinate of the top-left corner of the crop\n",
    "        target_height (int): Height of the crop\n",
    "        target_width (int): Width of the crop\n",
    "        \n",
    "    Returns:\n",
    "        cropped_image: 3-D tensor containing the cropped image\n",
    "    '''\n",
    "    \n",
    "    return tf.cast(\n",
    "        tf.image.crop_to_bounding_box(\n",
    "            image,\n",
    "            offset_height, offset_width,\n",
    "            target_height, target_width),\n",
    "        image.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_central(image, target_height, target_width):\n",
    "    '''Crops the central patch of an image\n",
    "    \n",
    "    Args:\n",
    "        image: 3-D image `Tensor`\n",
    "        target_height (int): Height of the crop\n",
    "        target_width (int): Width of the crop\n",
    "        \n",
    "    Returns:\n",
    "        cropped_image: 3-D tensor containing the central crop of the image\n",
    "    '''\n",
    "    \n",
    "    shape = tf.shape(input=image)\n",
    "    height, width = shape[0], shape[1]\n",
    "\n",
    "    offset_height = (height - target_height) // 2\n",
    "    offset_width = (width - target_width) // 2\n",
    "    \n",
    "    return crop_image(\n",
    "        image,\n",
    "        offset_height, offset_width,\n",
    "        target_height, target_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_corner_upper_left(image, target_height, target_width):\n",
    "    '''Crops the upper left corner patch of an image\n",
    "    \n",
    "    Args:\n",
    "        image: 3-D image `Tensor`\n",
    "        target_height (int): Height of the crop\n",
    "        target_width (int): Width of the crop\n",
    "        \n",
    "    Returns:\n",
    "        cropped_image: 3-D tensor containing the crop at the upper left corner position of the image\n",
    "    '''\n",
    "    \n",
    "    shape = tf.shape(input=image)\n",
    "    height, width = shape[0], shape[1]\n",
    "\n",
    "    offset_height = 0\n",
    "    offset_width = 0\n",
    "\n",
    "    return crop_image(\n",
    "        image,\n",
    "        offset_height, offset_width,\n",
    "        target_height, target_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_corner_upper_right(image, target_height, target_width):\n",
    "    '''Crops the upper right corner patch of an image\n",
    "    \n",
    "    Args:\n",
    "        image: 3-D image `Tensor`\n",
    "        target_height (int): Height of the crop\n",
    "        target_width (int): Width of the crop\n",
    "        \n",
    "    Returns:\n",
    "        cropped_image: 3-D tensor containing the crop at the upper right corner position of the image\n",
    "    '''\n",
    "    \n",
    "    shape = tf.shape(input=image)\n",
    "    height, width = shape[0], shape[1]\n",
    "\n",
    "    offset_height = 0\n",
    "    offset_width = (width - target_width)\n",
    "\n",
    "    return crop_image(\n",
    "        image,\n",
    "        offset_height, offset_width,\n",
    "        target_height, target_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_corner_lower_right(image, target_height, target_width):\n",
    "    '''Crops the lower right corner patch of an image\n",
    "    \n",
    "    Args:\n",
    "        image: 3-D image `Tensor`\n",
    "        target_height (int): Height of the crop\n",
    "        target_width (int): Width of the crop\n",
    "        \n",
    "    Returns:\n",
    "        cropped_image: 3-D tensor containing the crop at the lower right corner position of the image\n",
    "    '''\n",
    "    \n",
    "    shape = tf.shape(input=image)\n",
    "    height, width = shape[0], shape[1]\n",
    "\n",
    "    offset_height = (height - target_height)\n",
    "    offset_width = (width - target_width)\n",
    "\n",
    "    return crop_image(\n",
    "        image,\n",
    "        offset_height, offset_width,\n",
    "        target_height, target_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_corner_lower_left(image, target_height, target_width):\n",
    "    '''Crops the lower left corner patch of an image\n",
    "    \n",
    "    Args:\n",
    "        image: 3-D image `Tensor`\n",
    "        target_height (int): Height of the crop\n",
    "        target_width (int): Width of the crop\n",
    "        \n",
    "    Returns:\n",
    "        cropped_image: 3-D tensor containing the crop at the lower left corner position of the image\n",
    "    '''\n",
    "    \n",
    "    shape = tf.shape(input=image)\n",
    "    height, width = shape[0], shape[1]\n",
    "\n",
    "    offset_height = (height - target_height)\n",
    "    offset_width = 0\n",
    "\n",
    "    return crop_image(\n",
    "        image,\n",
    "        offset_height, offset_width,\n",
    "        target_height, target_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_random(image, target_height, target_width):\n",
    "    '''Crops a random patch of an image\n",
    "    \n",
    "    Args:\n",
    "        image: 3-D image `Tensor`\n",
    "        target_height (int): Height of the crop\n",
    "        target_width (int): Width of the crop\n",
    "        \n",
    "    Returns:\n",
    "        cropped_image: 3-D tensor containing a crop at a random position of the image\n",
    "    '''\n",
    "    \n",
    "    shape = tf.shape(input=image)\n",
    "    height, width = shape[0], shape[1]\n",
    "\n",
    "    offset_height = tf.random.uniform((1,), maxval=(height - target_height), dtype=tf.dtypes.int32)[0]\n",
    "    offset_width = tf.random.uniform((1,), maxval=(width - target_width), dtype=tf.dtypes.int32)[0]\n",
    "    \n",
    "    return crop_image(\n",
    "        image,\n",
    "        offset_height, offset_width,\n",
    "        target_height, target_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flip a given image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_horizontally(image):\n",
    "    '''Simple wrapper for `tf.image.flip_up_down`\n",
    "    \n",
    "    Args:\n",
    "        image: 3-D image `Tensor`\n",
    "        \n",
    "    Returns:\n",
    "        flipped_image: 3-D tensor containing the horizontally flipped image\n",
    "    '''\n",
    "    \n",
    "    return tf.image.flip_up_down(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_vertically(image):\n",
    "    '''Simple wrapper for `tf.image.flip_left_right`\n",
    "    \n",
    "    Args:\n",
    "        image: 3-D image `Tensor`\n",
    "        \n",
    "    Returns:\n",
    "        flipped_image: 3-D tensor containing the vertically flipped image\n",
    "    '''\n",
    "    \n",
    "    return tf.image.flip_left_right(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alter the intensities of the RGB channels of a given image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approximate the principal components of the RGB channels from a set of pixel values from the\n",
    "# training dataset using Singular Value Decomposition (SVD)\n",
    "\n",
    "# Number of samples to use for approximation of the covariance matrix of the RGB channels\n",
    "NUM_SAMPLES = 10000\n",
    "\n",
    "# Construct a matrix containing all pixels within `NUM_SAMPLES` samples randomly drawn from the\n",
    "# training dataset with the dimensions 'num_pixels' * 'num_channels'\n",
    "rgb_values = None\n",
    "for record in ilsvrc2012_train_raw.shuffle(buffer_size=1000).take(NUM_SAMPLES):\n",
    "    image = tf.dtypes.cast(record[ILSVRC2012_IMG_KEY], tf.dtypes.float32)\n",
    "    \n",
    "    if rgb_values is None:\n",
    "        rgb_values = tf.expand_dims(tf.math.reduce_mean(image, axis=[0, 1]), axis=0)\n",
    "    else:\n",
    "        rgb_values = tf.concat(\n",
    "            [rgb_values, tf.expand_dims(tf.math.reduce_mean(image, axis=[0, 1]), axis=0)], axis=0)\n",
    "\n",
    "# Offset / bias correction\n",
    "rgb_values = rgb_values - tf.reduce_mean(rgb_values, axis=0)\n",
    "\n",
    "# Standard deviation normalization\n",
    "rgb_values = rgb_values / tf.math.sqrt(tf.reduce_mean(rgb_values ** 2, axis=0))\n",
    "\n",
    "# Calculate the covariance matrix of `rgb_values`\n",
    "rgb_cov = tf.linalg.matmul(rgb_values, rgb_values, transpose_a=True) / NUM_SAMPLES\n",
    "\n",
    "# Singular Value Decomposition (SVD)\n",
    "s, u, v = tf.linalg.svd(rgb_cov)\n",
    "\n",
    "# Be s, v, u the singular values, right singular vectors and left singular vectors of M. Then the\n",
    "# following holds true:\n",
    "#     Mt * M = (u * s * vt)t * u * s * vt    (I)\n",
    "#            = v * st * ut * u * s * vt      (II)\n",
    "#            = v * (s ** 2) * vt             (III)\n",
    "# Thus it can be seen that v are the eigenvectors and s ** 2 are the eigenvalues of Mt * M. In the\n",
    "# case of the singular value decomposition of the covariance matrix of M the right singular vectors\n",
    "# are consequently eigenvectors of the zero-mean centered, normalized M and the singular values are\n",
    "# the square root of the respective eigenvalues. (Generally, the right singular vectors can be\n",
    "# interpreted as a orthonormal base along the main variance axes of the matrix (i.e. the transformation\n",
    "# space) while the left singular values depict the orthonormal base along the same axes in the\n",
    "# codomain space.)\n",
    "ILSVRC2012_TRAIN_RGB_EIGENVALUES = s ** 2\n",
    "ILSVRC2012_TRAIN_RGB_EIGENVECTORS = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_rgb(image, axis, stddev=0.1):\n",
    "    '''Shifts the itensities of the RGB channels of a given image by a random value along a given axis\n",
    "    \n",
    "    Args:\n",
    "        image: 3-D image `Tensor`\n",
    "        axis: Axis along which to perform the shift of the RGB values (i.e. if e.g. a value of\n",
    "            [1., 1., 1.] is provided, the shift is applied to all channels homogenously); has to be\n",
    "            of shape (None, 3); if multiple axes are provided, a shift is performed along each axis\n",
    "            respectively\n",
    "        stddev (float, optional): Standard deviation of the Gaussian to draw the weights from\n",
    "        \n",
    "    Returns:\n",
    "        rgb_corrected_image: 3-D tensor containing the RGB-shifted image\n",
    "    '''\n",
    "    \n",
    "    image_dtype = image.dtype\n",
    "    \n",
    "    image = tf.dtypes.cast(image, tf.dtypes.float32)\n",
    "    axis = tf.dtypes.cast(axis, tf.dtypes.float32)\n",
    "    \n",
    "    if len(axis.shape) == 1:\n",
    "        axis = tf.expand_dims(axis, 0)\n",
    "            \n",
    "    # Sample the weights for the different principal components from a Gaussian with mean zero and\n",
    "    # standard deviation `stddev`\n",
    "    # Annotation: The weights for each principal component are drawn exactly once per image.\n",
    "    weights = tf.random.normal(shape=(axis.shape[1], ), mean=0.0, stddev=stddev)\n",
    "    \n",
    "    rgb_corrected_image = image + tf.math.reduce_sum(\n",
    "        tf.math.multiply(tf.transpose(tf.broadcast_to(weights, axis.shape)), axis) * (RGB_MAX_VAL - RGB_MIN_VAL) / 2, axis=0)\n",
    "        \n",
    "    # Cut off invalid channel values\n",
    "    rgb_corrected_image = tf.math.maximum(tf.math.minimum(rgb_corrected_image, RGB_MAX_VAL), RGB_MIN_VAL)\n",
    "    \n",
    "    return tf.dtypes.cast(rgb_corrected_image, image_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General preprocessing applicable to all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_preprocessing(record, flip=False):\n",
    "    '''Preprocessing steps applicable to all images\n",
    "    \n",
    "    Preprocessing steps applicable to all images; includes horizontal flipping\n",
    "    \n",
    "    Args:\n",
    "        record: (`image`, `label`) tuple\n",
    "        flip (optional): Indicator whether to flip the image\n",
    "        \n",
    "    Returns:\n",
    "        processed_image: 3-D tensor containing the processed image\n",
    "        label: Label belonging to `processed_image`\n",
    "    '''\n",
    "    \n",
    "    image = record[0]\n",
    "    label = record[1]\n",
    "    \n",
    "    if flip:\n",
    "        processed_image = flip_horizontally(image)\n",
    "    else:\n",
    "        processed_image = image\n",
    "    \n",
    "    return (processed_image, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing dependent on whether the images are used for training or evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_preprocessing(record):\n",
    "    '''Preprocessing steps applicable only to training images\n",
    "    \n",
    "    Preprocessing steps applicable only to training images; includes cropping of random image patches\n",
    "    and shifts of the itensities of the RGB channels along the (approximated) principal components of\n",
    "    the set of the mean pixel values per image in the training dataset scaled by their corresponding\n",
    "    eigenvalues times a random variable drawn from a Gaussian with mean zero and standard deviation 0.1\n",
    "    \n",
    "    Args:\n",
    "        record: (`image`, `label`) tuple\n",
    "        \n",
    "    Returns:\n",
    "        processed_image: 3-D tensor containing the processed image\n",
    "        label: Label belonging to `processed_image`\n",
    "    '''\n",
    "            \n",
    "    image = record[0]\n",
    "    label = record[1]\n",
    "    \n",
    "    # RGB shift\n",
    "    processed_image = shift_rgb(\n",
    "            image,\n",
    "            tf.math.multiply(\n",
    "                ILSVRC2012_TRAIN_RGB_EIGENVECTORS,\n",
    "                tf.transpose(tf.broadcast_to(ILSVRC2012_TRAIN_RGB_EIGENVALUES, ILSVRC2012_TRAIN_RGB_EIGENVECTORS.shape))\n",
    "            )\n",
    "    )\n",
    "    \n",
    "    # Random cropping\n",
    "    processed_image = crop_random(processed_image, CROP_SIZE_H, CROP_SIZE_W)\n",
    "    \n",
    "    return (processed_image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_preprocessing(record, crop_mode):\n",
    "    '''Preprocessing steps applicable only to test images\n",
    "    \n",
    "    Preprocessing steps applicable only to test images; includes cropping of center and corner\n",
    "    image patches\n",
    "    \n",
    "    Args:\n",
    "        record: (`image`, `label`) tuple\n",
    "        crop_mode (int): Indicates whether to crop at the center or the corners of the image ([0:3]\n",
    "            corners (clockwise starting at the upper left corner) and [4] image center)\n",
    "            \n",
    "    Returns:\n",
    "        processed_image: 3-D tensor containing the processed image\n",
    "        label: Label belonging to `processed_image`\n",
    "    '''\n",
    "\n",
    "    image = record[0]\n",
    "    label = record[1]\n",
    "    \n",
    "    if crop_mode == 0:\n",
    "        processed_image = crop_corner_upper_left(image, CROP_SIZE_H, CROP_SIZE_W)\n",
    "    elif crop_mode == 1:\n",
    "        processed_image = crop_corner_upper_right(image, CROP_SIZE_H, CROP_SIZE_W)\n",
    "    elif crop_mode == 2:\n",
    "        processed_image = crop_corner_lower_right(image, CROP_SIZE_H, CROP_SIZE_W)\n",
    "    elif crop_mode == 3:\n",
    "        processed_image = crop_corner_lower_left(image, CROP_SIZE_H, CROP_SIZE_W)\n",
    "    else:\n",
    "        processed_image = crop_central(image, CROP_SIZE_H, CROP_SIZE_W)\n",
    "    \n",
    "    return (processed_image, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a raw dataset, construct an iterator over the preprocessed and augmented records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_augment(dataset,\n",
    "                        batch_size,\n",
    "                        synset_level=ILSVRC2012_SPECIES_LABEL_LEVEL,\n",
    "                        hypernym=None,\n",
    "                        is_train=False,\n",
    "                        num_rnd_crops=5,\n",
    "                        shuffle_buffer_size=10000,\n",
    "                        num_epochs=1):\n",
    "    '''Given raw dataset, construct an iterator over the preprocessed and augmented records\n",
    "    \n",
    "    Args:\n",
    "        dataset: Dataset containing raw records\n",
    "        batch_size: Number of samples per batch\n",
    "        synset_level (optional): Specifier of the synset level (i.e. fineness of label resolution)\n",
    "            to use (defaults to the finest possible resolution (i.e. species level for the ILSVRC2012\n",
    "            dataset)\n",
    "        hypernym (optional): Identifier of the parental (hypernym) category whose subordinate (hyponym)\n",
    "            labels are to be included in the dataset (only evaluated below the root level, i.e. if\n",
    "            `synset_level` is greater than `0`; value `None` (default) indicates that all categories\n",
    "            are to be included; all records with other labels are discarded)\n",
    "        is_train (optional): Indicator whether the input is for training\n",
    "        num_rnd_crops (optional): Number of random crops perform per image (each crop is subsequently\n",
    "            flipped vertically as well, resulting in a total augmentation of 2 * `num_rnd_crops` per\n",
    "            image; only evaluated if `is_train`is set to True)\n",
    "        shuffle_buffer_size (optional): Size of the buffer to use when shuffling records (only used\n",
    "            if `is_train` is set to True)\n",
    "        num_epochs (optional): Number of epochs to repeat the dataset (only used when `is_train` is\n",
    "            set to True)\n",
    "            \n",
    "    Returns:\n",
    "        dataset: Dataset of (`image`, `label`) pairs ready for iteration\n",
    "    '''\n",
    "    \n",
    "    # Cut off invalid values for `synset_level`\n",
    "    synset_level = max(0, min(ILSVRC2012_SPECIES_LABEL_LEVEL, synset_level))\n",
    "    \n",
    "    # Get the maximum label (called 'label depth' in Tensorflow) for one-hot encoding (cf. below)\n",
    "    label_depth = len(ILSVRC2012_SYNSET_MAP.get_all_synsets_of_level(synset_level))\n",
    "\n",
    "    # Convert each record to the form (image, label) and encode the latter at the same time\n",
    "    dataset = dataset.map(\n",
    "        lambda record: (record[ILSVRC2012_IMG_KEY],\n",
    "                        tf_ilsvrc2012_resolve_hypernym_encoded(record[ILSVRC2012_LABEL_KEY], synset_level)),\n",
    "        num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    if (synset_level != 0) and (hypernym is not None):\n",
    "        # Check, whether `hypernym` is compatible with `synset_level`\n",
    "        if (ILSVRC2012_SYNSET_MAP.synset_level(hypernym) == synset_level - 1):\n",
    "            hyponyms = ILSVRC2012_SYNSET_MAP.hyponyms(hypernym)\n",
    "\n",
    "            if hyponyms:\n",
    "                # Apply filter w/ regards to the parental (coarse) category (i.e. filter out all images\n",
    "                # that don't belong to a given parent category)\n",
    "                dataset = dataset.filter(\n",
    "                    lambda _, label: tf.math.reduce_any(\n",
    "                        [tf.math.equal(label, ilsvrc2012_encode(hyponym)[0]) for hyponym in hyponyms]))\n",
    "    \n",
    "    # One-hot encode the remaining entries\n",
    "    dataset = dataset.map(\n",
    "        lambda image, label: (image, tf.one_hot(label, label_depth)),\n",
    "        num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    # Parse the raw records into images and labels and augment the dataset as described in\n",
    "    # (Krizhevsky et al., 2012) and (Sermanet et al., 2014)\n",
    "    \n",
    "    # Repeat each image twice (once per flip)\n",
    "    dataset = dataset.enumerate().interleave(\n",
    "        lambda _, record: tf.data.Dataset.from_tensors(record).repeat(2),\n",
    "        cycle_length=1,\n",
    "        num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    # General preprocessing applicable to all images\n",
    "    dataset = dataset.enumerate().map(\n",
    "        lambda idx, record: general_preprocessing(record, flip=tf.dtypes.cast(idx % 2, tf.dtypes.bool)),\n",
    "        num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        \n",
    "    # Mode dependent augmentation\n",
    "    if is_train:\n",
    "        # Repeat each image `num_rnd_crops` times (once per crop)\n",
    "        dataset = dataset.enumerate().interleave(\n",
    "            lambda _, record: tf.data.Dataset.from_tensors(record).repeat(num_rnd_crops),\n",
    "            cycle_length=1,\n",
    "            num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "        dataset = dataset.enumerate().map(\n",
    "            lambda _, record: train_preprocessing(record),\n",
    "            num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    else:\n",
    "        # Repeat each image five times (once per crop)\n",
    "        dataset = dataset.enumerate().interleave(\n",
    "            lambda _, record: tf.data.Dataset.from_tensors(record).repeat(5),\n",
    "            cycle_length=1,\n",
    "            num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        \n",
    "        dataset = dataset.enumerate().map(\n",
    "            lambda idx, record: test_preprocessing(record, crop_mode=idx%5),\n",
    "            num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    if is_train:\n",
    "        # Shuffle records before repeating to respect epoch boundaries\n",
    "        dataset = dataset.shuffle(buffer_size=shuffle_buffer_size)\n",
    "        # Repeats the dataset for the number of epochs to train\n",
    "        dataset = dataset.repeat(num_epochs)\n",
    "    \n",
    "    # Batching\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    # Operations between the final prefetch and the get_next call to the iterator will happen\n",
    "    # synchronously during run time. Manual prefetching at this point backgrounds all of the above\n",
    "    # processing work and helps keep it out of the critical training path.\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark the performance of the preprocessing pipeline\n",
    "\n",
    "# Number of samples to use for the benchmark (higher numbers result in a lower bias from onetime\n",
    "# operations but increase the computation time)\n",
    "NUM_SAMPLES = 1000\n",
    "\n",
    "ilsvrc2012_train = process_and_augment(ilsvrc2012_train_raw,\n",
    "                                       batch_size=1,\n",
    "                                       synset_level=ILSVRC2012_SPECIES_LABEL_LEVEL,\n",
    "                                       hypernym='aquatic_bird',\n",
    "                                       is_train=True,\n",
    "                                       num_rnd_crops=5,\n",
    "                                       shuffle_buffer_size=10000,\n",
    "                                       num_epochs=1)\n",
    "\n",
    "start_time_raw = time.perf_counter()\n",
    "for record in ilsvrc2012_train_raw.take(NUM_SAMPLES):\n",
    "    continue\n",
    "end_time_raw = time.perf_counter()\n",
    "\n",
    "mean_time_raw = (end_time_raw - start_time_raw) / NUM_SAMPLES\n",
    "print('Mean time per sample (raw): {} s'.format(mean_time_raw))\n",
    "\n",
    "start_time_processed = time.perf_counter()\n",
    "for record in ilsvrc2012_train.take(NUM_SAMPLES):\n",
    "    continue\n",
    "end_time_processed = time.perf_counter()\n",
    "\n",
    "mean_time_processed = (end_time_processed - start_time_processed) / NUM_SAMPLES\n",
    "print('Mean time per sample (preprocessed): {} s'.format(mean_time_processed))\n",
    "\n",
    "mean_time_diff = mean_time_processed - mean_time_raw\n",
    "print('Time difference per sample: {} s'.format(mean_time_diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Model template (VGG)\n",
    "<a id='template'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the basic network architecture employed for both the [composed model](#compnet) as well as for the [benchmark](#benchmark), it was decided to use the VGG architecture following (Simonyan et al., 2015). In this section, a template is provided that can be used to generate instances of the aforementioned model with customizable hyperparameters such as the number of hidden layers or neurons per layer.\n",
    "\n",
    "Criteria that were taken into account when selecting the basic network architecture:\n",
    "- a) Simplicity / Leanness (i.e. no inferred knowledge in the architecture for the same [reasons](#compnet) mentioned when arguing about the composed model's architecture)\n",
    "- b) Existence of reference values in literature\n",
    "- c) Scalability (so that we could employ the same architecture for the composed model as well as for the benchmark for comparative reasons)\n",
    "- d) Contemporary performance levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_model_from_template(input_shape,\n",
    "                            num_classes,\n",
    "                            num_conv_layers,\n",
    "                            num_conv_channels,\n",
    "                            num_fc_layers,\n",
    "                            num_fc_neurons):\n",
    "    '''Constructs a VGG network as described in (Simonyan et al., 2015) from template\n",
    "    \n",
    "    Constructs a VGG network as described in (Simonyan et al., 2015) with customizable hyperparameters\n",
    "    from a template model\n",
    "    \n",
    "    Args:\n",
    "        input_shape: Dimensions of the input to the first layer\n",
    "        num_classes (int): Number of classes (translates to dimensions of the output)\n",
    "        num_conv_layers (int): Number of convolutional layers\n",
    "        num_conv_channels: Number of channels per convolutional layer; can be specified either as a\n",
    "            list with one entry for every convolutional layer or as a single value (in case of the\n",
    "            latter, the same amount of channels is used for all convolutional layers)\n",
    "        num_fc_layers (int): Number of fully connected layers\n",
    "        num_fc_neurons: Number of neruons per fully connected layer; can be specified either as a\n",
    "            list with one entry for every fully connected layer or as a single value (in case of the\n",
    "            latter, the same amount of neurons is used for all convolutional layers)\n",
    "    \n",
    "    Returns:\n",
    "        model: VGG network with the specified hyperparameters\n",
    "        \n",
    "    Raises:\n",
    "        TypeError: If one of the input arguments is of the wrong type\n",
    "        ValueError: If invalid values are specified for one or more input arguments\n",
    "    '''\n",
    "    \n",
    "    if not isinstance(input_shape, list):\n",
    "        raise TypeError(\n",
    "            '`input_shape` is expected to be of type `list`. Is of type {}.\\n'.format(type(input_shape))\n",
    "        )\n",
    "    if not input_shape:\n",
    "        raise ValueError(\n",
    "            '`input_shape` may not be empty.\\n'\n",
    "        )\n",
    "    if any([dim <= 0 for dim in input_shape]):\n",
    "        raise ValueError(\n",
    "            'All entries of `input_shape` must be greater than zero.\\n'\n",
    "        )\n",
    "    if not isinstance(num_classes, int):\n",
    "        raise TypeError(\n",
    "            '`num_classes` is expected to be of type `int`. Is of type {}.\\n'.format(type(num_classes))\n",
    "        )\n",
    "    if num_classes <= 0:\n",
    "        raise ValueError(\n",
    "            '`num_classes` must be greater than zero.\\n'\n",
    "        )\n",
    "    if not isinstance(num_conv_layers, int):\n",
    "        raise TypeError(\n",
    "            '`num_conv_layers` is expected to be of type `int`. Is of type {}.\\n'.format(type(num_conv_layers))\n",
    "        )\n",
    "    if num_conv_layers <= 0:\n",
    "        raise ValueError(\n",
    "            '`num_conv_layers` must be greater than zero.\\n'\n",
    "        )\n",
    "    if not (isinstance(num_conv_channels, int) or isinstance(num_conv_channels, list)):\n",
    "        raise TypeError(\n",
    "            '`num_conv_channels` is expected to be either of type `int` or `list`.'\n",
    "            'Is of type {}.\\n'.format(type(num_conv_channels))\n",
    "        )\n",
    "    if isinstance(num_conv_channels, int):\n",
    "        if num_conv_channels <= 0:\n",
    "            raise ValueError(\n",
    "                '`num_conv_channels` must be greater than zero.\\n'\n",
    "            )\n",
    "    if isinstance(num_conv_channels, list):\n",
    "        if len(num_conv_channels) != num_conv_layers:\n",
    "            raise ValueError(\n",
    "                'The number of entries of `num_conv_channels` must match `num_conv_layers`.\\n'\n",
    "            )\n",
    "        if not all([isinstance(num_neurons, int) for num_neurons in num_conv_channels]):\n",
    "            raise TypeError(\n",
    "                'All entries of `num_conv_channels` must be of type `int`.\\n'\n",
    "            )\n",
    "        if any([num_neurons <= 0 for num_neurons in num_conv_channels]):\n",
    "            raise ValueError(\n",
    "                'All entries of `num_conv_channels` must be greater than zero.\\n'\n",
    "            )\n",
    "    if not isinstance(num_fc_layers, int):\n",
    "        raise TypeError(\n",
    "            '`num_fc_layers` is expected to be of type `int`. Is of type {}.\\n'.format(type(num_fc_layers))\n",
    "        )\n",
    "    if num_fc_layers <= 0:\n",
    "        raise ValueError(\n",
    "            '`num_fc_layers` must be greater than zero.\\n'\n",
    "        )\n",
    "    if not (isinstance(num_fc_neurons, int) or isinstance(num_fc_neurons, list)):\n",
    "        raise TypeError(\n",
    "            '`num_fc_neurons` is expected to be either of type `int` or `list`.'\n",
    "            'Is of type {}.\\n'.format(type(num_fc_neurons))\n",
    "        )\n",
    "    if isinstance(num_fc_neurons, int):\n",
    "        if num_fc_neurons <= 0:\n",
    "            raise ValueError(\n",
    "                '`num_fc_neurons` must be greater than zero.\\n'\n",
    "            )\n",
    "    if isinstance(num_fc_neurons, list):\n",
    "        if len(num_fc_neurons) != num_fc_layers:\n",
    "            raise ValueError(\n",
    "                'The number of entries of `num_fc_neurons` must match `num_fc_layers`.\\n'\n",
    "            )\n",
    "        if not all([isinstance(num_neurons, int) for num_neurons in num_fc_neurons]):\n",
    "            raise TypeError(\n",
    "                'All entries of `num_fc_neurons` must be of type `int`.\\n'\n",
    "            )\n",
    "        if any([num_neurons <= 0 for num_neurons in num_fc_neurons]):\n",
    "            raise ValueError(\n",
    "                'All entries of `num_fc_neurons` must be greater than zero.\\n'\n",
    "            )\n",
    "            \n",
    "    # Convert `num_conv_channels` and / or `num_fc_neurons` to a list if provided as a single int\n",
    "    if isinstance(num_conv_channels, int):\n",
    "        num_conv_channels = [num_conv_channels] * num_conv_layers\n",
    "    if isinstance(num_fc_neurons, int):\n",
    "        num_fc_neurons = [num_fc_neurons] * num_fc_neurons\n",
    "        \n",
    "    # Define the convolutional layers after which to insert MaxOut layers based on `num_conv_layers`\n",
    "    # in accordance to (Simonyan et al., 2015)\n",
    "    if num_conv_layers <= 8:\n",
    "        MAXPOOL_LAYERS = [1, 2, 4, 6]\n",
    "    elif num_conv_layers <= 10:\n",
    "        MAXPOOL_LAYERS = [2, 4, 6, 8]\n",
    "    elif num_conv_layers <= 13:\n",
    "        MAXPOOL_LAYERS = [2, 4, 7, 10]\n",
    "    else:\n",
    "        MAXPOOL_LAYERS = [2, 4, 8, 12]\n",
    "    \n",
    "    # Construct the network with the specified hyperparameters from a model template\n",
    "    # Note: We imply a combination of Dropout and MaxNorm for weight regularization as is reported\n",
    "    # in (Srivastava et al., 2014) to be most effective. Furthermore, we also apply Dropout to the\n",
    "    # convolutional layers to facilitate the discovery of informative features as described in\n",
    "    # (Park et al., 2016).\n",
    "\n",
    "    # Input specification\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    # Convolutional layer\n",
    "    x = tf.keras.layers.Conv2D(filters=num_conv_channels[0],\n",
    "                               kernel_size=(3, 3),\n",
    "                               strides=1,\n",
    "                               padding='same',\n",
    "                               activation='relu',\n",
    "                               use_bias=True,\n",
    "                               kernel_regularizer=tf.keras.regularizers.l2(l=5e-4),\n",
    "                               bias_regularizer=tf.keras.regularizers.l2(l=5e-4))(inputs)\n",
    "    \n",
    "    for layer in range(1, num_conv_layers):\n",
    "        # Check when to insert MaxPool and Dropout layers in accordance to (Simonyan et al., 2015)\n",
    "        if layer in MAXPOOL_LAYERS:\n",
    "            # MaxPool layer\n",
    "            x = tf.keras.layers.MaxPool2D(pool_size=(2, 2),\n",
    "                                          strides=(2, 2),\n",
    "                                          padding='same')(x)\n",
    "\n",
    "            # Dropout layer\n",
    "            x = tf.keras.layers.Dropout(rate=0.1)(x)\n",
    "        \n",
    "        # Convolutional layer\n",
    "        x = tf.keras.layers.Conv2D(filters=num_conv_channels[layer],\n",
    "                                   kernel_size=(3, 3),\n",
    "                                   strides=1,\n",
    "                                   padding='same',\n",
    "                                   activation='relu',\n",
    "                                   use_bias=True,\n",
    "                                   kernel_regularizer=tf.keras.regularizers.l2(l=5e-4),\n",
    "                                   bias_regularizer=tf.keras.regularizers.l2(l=5e-4))(x)\n",
    "\n",
    "    # MaxPool layer\n",
    "    x = tf.keras.layers.MaxPool2D(pool_size=(2, 2),\n",
    "                                  strides=(2, 2),\n",
    "                                  padding='same')(x)\n",
    "    \n",
    "    # Transition between convolutional and fully connected layers\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "    # Dropout layer\n",
    "    x = tf.keras.layers.Dropout(rate=0.5)(x)\n",
    "    \n",
    "    for layer in range(num_fc_layers):\n",
    "        # Fully connected layer\n",
    "        x = tf.keras.layers.Dense(units=num_fc_neurons[layer],\n",
    "                                  activation='relu',\n",
    "                                  use_bias=True,\n",
    "                                  kernel_regularizer=tf.keras.regularizers.l2(l=5e-4),\n",
    "                                  bias_regularizer=tf.keras.regularizers.l2(l=5e-4))(x)\n",
    "\n",
    "        # Dropout layer\n",
    "        x = tf.keras.layers.Dropout(rate=0.5)(x)\n",
    "\n",
    "    # Softmax output layer\n",
    "    outputs = tf.keras.layers.Dense(units=num_classes,\n",
    "                                    activation='softmax',\n",
    "                                    use_bias=True,\n",
    "                                    kernel_regularizer=tf.keras.regularizers.l2(l=5e-4),\n",
    "                                    bias_regularizer=tf.keras.regularizers.l2(l=5e-4))(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Composed Network (CompNet)\n",
    "<a id='compnet'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we examine the performance of a composed model on the ILSVRC2012 animal subset. \n",
    "\n",
    "The structure of the model is based on the inherent structure of the ILSVRC2012 animal subset, i.e. four interconnected \"layers\" of classifiers where the predictions of the first layer are used to route the inputs to the corresponding sub-modules of the second, more specialized layer and so on. For simplicity, we keep the basic architecture and hyperparameters for each sub-module the same (i.e. we don't perform inidividual hyperparameter tuning). Furthermore, for comparability with results reported in literature as well as our own benchmark (cf. below), we employ the basic VGG architecture as described by (Simonyan et al., 2015) in a downscaled form so that the total number of trainable parameters across all sub-modules roughly matches the benchmark.\n",
    "\n",
    "It should be noted at this point, that, even though there are several promising approaches to be found in literature regarding possible improvements of the resilience of hierarchically composed models (cf. e.g. (Fergus et al., 2010), (Deng et al., 2014) or (Roy et al., 2019)), we deliberately avoided incorporating these ideas into our work as the goal of this project is to examine the question whether modularisation of networks in general is a feasible approach and we want to keep our results as unbiased as possible in this regard (i.e. not \"unfairly\" improving our approach with regard to the benchmark). Nevertheless, it should also be noted that in doing so, we leave lots of room for improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "<a id='compnet_model'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've got as many specialist modules per layer as there are categories in the preceeding one. The downstream models are grouped in an array in order of their respective hypernym label (i.e. 0..n where n is the number of parental categories) to facilitate routing between the layers by enabling the direct utilization of the prediction of the preceeding layer for indexing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Phylum layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phylum_model = vgg_model_from_template(input_shape=[224, 224, 3],\n",
    "                                       num_classes=ILSVRC2012_NUM_LABELS_PHYLUM_LAYER,\n",
    "                                       num_conv_layers=8,\n",
    "                                       num_conv_channels=[32, 64, 128, 128,\n",
    "                                                          256, 256, 256, 256],\n",
    "                                       num_fc_layers=2,\n",
    "                                       num_fc_neurons=128)\n",
    "phylum_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Categorical Cross Entropy as loss function\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "# Define metrics to watch during training\n",
    "metrics = [tf.keras.metrics.CategoricalAccuracy(),\n",
    "           tf.keras.metrics.TopKCategoricalAccuracy(k=5),\n",
    "           tf.keras.metrics.CategoricalCrossentropy(),\n",
    "           tf.keras.metrics.AUC()]\n",
    "\n",
    "# Use Adam (Kingma et al., 2017) as optimizer during training\n",
    "# Annotation: We don't set `learning_rate` here as this is automatically handled by the\n",
    "# LearningRateScheduler (cf. callback section below).\n",
    "optimizer = tf.keras.optimizers.Adam(beta_1=0.9,\n",
    "                                     beta_2=0.999,\n",
    "                                     epsilon=1e-07)\n",
    "\n",
    "phylum_model.compile(loss=loss, metrics=metrics, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively: Restore model from checkpoint\n",
    "# phylum_model = tf.keras.models.load_model(CKPT_DIR + 'compnet_phylum')\n",
    "# phylum_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_models = []\n",
    "\n",
    "for idx in range(ILSVRC2012_NUM_LABELS_PHYLUM_LAYER):\n",
    "    model = vgg_model_from_template(input_shape=[224, 224, 3],\n",
    "                                    num_classes=ILSVRC2012_NUM_LABELS_CLASS_LAYER,\n",
    "                                    num_conv_layers=8,\n",
    "                                    num_conv_channels=[32, 64, 128, 128,\n",
    "                                                       256, 256, 256, 256],\n",
    "                                    num_fc_layers=2,\n",
    "                                    num_fc_neurons=128)\n",
    "    class_models.append(model)\n",
    "    \n",
    "class_models[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(ILSVRC2012_NUM_LABELS_PHYLUM_LAYER):\n",
    "    # Use Categorical Cross Entropy as loss function\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "    # Define metrics to watch during training\n",
    "    metrics = [tf.keras.metrics.CategoricalAccuracy(),\n",
    "               tf.keras.metrics.TopKCategoricalAccuracy(k=5),\n",
    "               tf.keras.metrics.CategoricalCrossentropy(),\n",
    "               tf.keras.metrics.AUC()]\n",
    "\n",
    "    # Use Adam (Kingma et al., 2017) as optimizer during training\n",
    "    # Annotation: We don't set `learning_rate` here as this is automatically handled by the\n",
    "    # LearningRateScheduler (cf. callback section below).\n",
    "    optimizer = tf.keras.optimizers.Adam(beta_1=0.9,\n",
    "                                         beta_2=0.999,\n",
    "                                         epsilon=1e-07)\n",
    "    \n",
    "    # Compile the respective sub-module\n",
    "    class_models[idx].compile(loss=loss, metrics=metrics, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively: Restore models from checkpoint\n",
    "# class_models = []\n",
    "# for idx in range(ILSVRC2012_NUM_LABELS_PHYLUM_LAYER):\n",
    "#     model = tf.keras.models.load_model(CKPT_DIR + 'compnet_class_' + str(idx))\n",
    "#     class_models.append(model)\n",
    "#\n",
    "# class_models[0].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Order layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_models = []\n",
    "\n",
    "for idx in range(ILSVRC2012_NUM_LABELS_CLASS_LAYER):\n",
    "    model = vgg_model_from_template(input_shape=[224, 224, 3],\n",
    "                                    num_classes=ILSVRC2012_NUM_LABELS_ORDER_LAYER,\n",
    "                                    num_conv_layers=8,\n",
    "                                    num_conv_channels=[32, 64, 128, 128,\n",
    "                                                       256, 256, 256, 256],\n",
    "                                    num_fc_layers=2,\n",
    "                                    num_fc_neurons=128)\n",
    "    order_models.append(model)\n",
    "\n",
    "order_models[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(ILSVRC2012_NUM_LABELS_CLASS_LAYER):\n",
    "    # Use Categorical Cross Entropy as loss function\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "    # Define metrics to watch during training\n",
    "    metrics = [tf.keras.metrics.CategoricalAccuracy(),\n",
    "               tf.keras.metrics.TopKCategoricalAccuracy(k=5),\n",
    "               tf.keras.metrics.CategoricalCrossentropy(),\n",
    "               tf.keras.metrics.AUC()]\n",
    "\n",
    "    # Use Adam (Kingma et al., 2017) as optimizer during training\n",
    "    # Annotation: We don't set `learning_rate` here as this is automatically handled by the\n",
    "    # LearningRateScheduler (cf. callback section below).\n",
    "    optimizer = tf.keras.optimizers.Adam(beta_1=0.9,\n",
    "                                         beta_2=0.999,\n",
    "                                         epsilon=1e-07)\n",
    "    \n",
    "    # Compile the respective sub-module\n",
    "    order_models[idx].compile(loss=loss, metrics=metrics, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively: Restore models from checkpoint\n",
    "# order_models = []\n",
    "# for idx in range(ILSVRC2012_NUM_LABELS_CLASS_LAYER):\n",
    "#     model = tf.keras.models.load_model(CKPT_DIR + 'compnet_order_' + str(idx))\n",
    "#     order_models.append(model)\n",
    "#\n",
    "# order_models[0].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Species layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_models = []\n",
    "\n",
    "for idx in range(ILSVRC2012_NUM_LABELS_ORDER_LAYER):\n",
    "    model = vgg_model_from_template(input_shape=[224, 224, 3],\n",
    "                                    num_classes=ILSVRC2012_NUM_LABELS_SPECIES_LAYER,\n",
    "                                    num_conv_layers=8,\n",
    "                                    num_conv_channels=[32, 64, 128, 128,\n",
    "                                                       256, 256, 256, 256],\n",
    "                                    num_fc_layers=2,\n",
    "                                    num_fc_neurons=128)\n",
    "    species_models.append(model)\n",
    "    \n",
    "species_models[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(ILSVRC2012_NUM_LABELS_ORDER_LAYER):\n",
    "    # Use Categorical Cross Entropy as loss function\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "    # Define metrics to watch during training\n",
    "    metrics = [tf.keras.metrics.CategoricalAccuracy(),\n",
    "               tf.keras.metrics.TopKCategoricalAccuracy(k=5),\n",
    "               tf.keras.metrics.CategoricalCrossentropy(),\n",
    "               tf.keras.metrics.AUC()]\n",
    "\n",
    "    # Use Adam (Kingma et al., 2017) as optimizer during training\n",
    "    # Annotation: We don't set `learning_rate` here as this is automatically handled by the\n",
    "    # LearningRateScheduler (cf. callback section below).\n",
    "    optimizer = tf.keras.optimizers.Adam(beta_1=0.9,\n",
    "                                         beta_2=0.999,\n",
    "                                         epsilon=1e-07)\n",
    "    \n",
    "    # Compile the respective sub-module\n",
    "    species_models[idx].compile(loss=loss, metrics=metrics, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively: Restore models from checkpoint\n",
    "# species_models = []\n",
    "# for idx in range(ILSVRC2012_NUM_LABELS_ORDER_LAYER):\n",
    "#     model = tf.keras.models.load_model(CKPT_DIR + 'compnet_species_' + str(idx))\n",
    "#     species_models.append(model)\n",
    "#\n",
    "# species_models[0].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "<a id='compnet_train'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Phylum layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ilsvrc2012_train_phylum = process_and_augment(ilsvrc2012_train_raw, batch_size=128, synset_level=ILSVRC2012_PHYLUM_LABEL_LEVEL, hypernym=None, is_train=True, num_rnd_crops=5, shuffle_buffer_size=10000, num_epochs=1)\n",
    "ilsvrc2012_val_phylum = process_and_augment(ilsvrc2012_val_raw, batch_size=128, synset_level=ILSVRC2012_PHYLUM_LABEL_LEVEL, hypernym=None, is_train=True, num_rnd_crops=5, shuffle_buffer_size=10000, num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EarlyStopping: Stop training early if no significant improvement in the monitored quantity is\n",
    "#     observed for at least `patience` epochs\n",
    "# LearningRateScheduler: Dynamically adapt the learning rate depending on the training epoch to\n",
    "#     facilitate accelerated learning during the first few epochs\n",
    "# ModelCheckpoint: Save the model after each epoch (if `save_best_only` is set to True, only keep\n",
    "#     the best model with regard to the monitored quantity)\n",
    "# TensorBoard: Enable TensorBoard visualization\n",
    "callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                              min_delta=0.01,\n",
    "                                              patience=3),\n",
    "             tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-03 if epoch < 2 else (1e-04 if epoch < 4 else 1e-05)),\n",
    "             tf.keras.callbacks.ModelCheckpoint(filepath=CKPT_DIR + 'compnet_phylum',\n",
    "                                                monitor='val_loss',\n",
    "                                                verbose=False,\n",
    "                                                save_best_only=True),\n",
    "             tf.keras.callbacks.TensorBoard(log_dir=LOG_DIR,\n",
    "                                            histogram_freq=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phylum_model.fit(x=ilsvrc2012_train_phylum,\n",
    "                 epochs=3,\n",
    "                 verbose=True,\n",
    "                 callbacks=callbacks,\n",
    "                 validation_data=ilsvrc2012_val_phylum,\n",
    "                 shuffle=True,\n",
    "                 validation_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ilsvrc2012_train_class = [process_and_augment(ilsvrc2012_train_raw, batch_size=128, synset_level=ILSVRC2012_CLASS_LABEL_LEVEL, hypernym=ilsvrc2012_decode(category, ILSVRC2012_PHYLUM_LABEL_LEVEL), is_train=True, num_rnd_crops=5, shuffle_buffer_size=10000, num_epochs=1) for category in range(ILSVRC2012_NUM_LABELS_PHYLUM_LAYER)]\n",
    "ilsvrc2012_val_class = [process_and_augment(ilsvrc2012_val_raw, batch_size=128, synset_level=ILSVRC2012_CLASS_LABEL_LEVEL, hypernym=ilsvrc2012_decode(category, ILSVRC2012_PHYLUM_LABEL_LEVEL), is_train=True, num_rnd_crops=5, shuffle_buffer_size=10000, num_epochs=1) for category in range(ILSVRC2012_NUM_LABELS_PHYLUM_LAYER)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(ILSVRC2012_NUM_LABELS_PHYLUM_LAYER):\n",
    "    # EarlyStopping: Stop training early if no significant improvement in the monitored quantity is\n",
    "    #     observed for at least `patience` epochs\n",
    "    # LearningRateScheduler: Dynamically adapt the learning rate depending on the training epoch to\n",
    "    #     facilitate accelerated learning during the first few epochs\n",
    "    # ModelCheckpoint: Save the model after each epoch (if `save_best_only` is set to True, only keep\n",
    "    #     the best model with regard to the monitored quantity)\n",
    "    # TensorBoard: Enable TensorBoard visualization\n",
    "    callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                  min_delta=0.01,\n",
    "                                                  patience=3),\n",
    "                 tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-03 if epoch < 2 else (1e-04 if epoch < 4 else 1e-05)),\n",
    "                 tf.keras.callbacks.ModelCheckpoint(filepath=CKPT_DIR + 'compnet_class_' + str(idx),\n",
    "                                                    monitor='val_loss',\n",
    "                                                    verbose=False,\n",
    "                                                    save_best_only=True),\n",
    "                 tf.keras.callbacks.TensorBoard(log_dir=LOG_DIR,\n",
    "                                                histogram_freq=1)]\n",
    "    \n",
    "    class_models[idx].fit(x=ilsvrc2012_train_class[idx],\n",
    "                          epochs=3,\n",
    "                          verbose=True,\n",
    "                          callbacks=callbacks,\n",
    "                          validation_data=ilsvrc2012_val_class[idx],\n",
    "                          shuffle=True,\n",
    "                          validation_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Order layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ilsvrc2012_train_order = [process_and_augment(ilsvrc2012_train_raw, batch_size=128, synset_level=ILSVRC2012_ORDER_LABEL_LEVEL, hypernym=ilsvrc2012_decode(category, ILSVRC2012_CLASS_LABEL_LEVEL), is_train=True, num_rnd_crops=5, shuffle_buffer_size=10000, num_epochs=1) for category in range(ILSVRC2012_NUM_LABELS_CLASS_LAYER)]\n",
    "ilsvrc2012_val_order = [process_and_augment(ilsvrc2012_val_raw, batch_size=128, synset_level=ILSVRC2012_ORDER_LABEL_LEVEL, hypernym=ilsvrc2012_decode(category, ILSVRC2012_CLASS_LABEL_LEVEL), is_train=True, num_rnd_crops=5, shuffle_buffer_size=10000, num_epochs=1) for category in range(ILSVRC2012_NUM_LABELS_CLASS_LAYER)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(ILSVRC2012_NUM_LABELS_CLASS_LAYER):  \n",
    "    # EarlyStopping: Stop training early if no significant improvement in the monitored quantity is\n",
    "    #     observed for at least `patience` epochs\n",
    "    # LearningRateScheduler: Dynamically adapt the learning rate depending on the training epoch to\n",
    "    #     facilitate accelerated learning during the first few epochs\n",
    "    # ModelCheckpoint: Save the model after each epoch (if `save_best_only` is set to True, only keep\n",
    "    #     the best model with regard to the monitored quantity)\n",
    "    # TensorBoard: Enable TensorBoard visualization\n",
    "    callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                  min_delta=0.01,\n",
    "                                                  patience=3),\n",
    "                 tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-03 if epoch < 2 else (1e-04 if epoch < 4 else 1e-05)),\n",
    "                 tf.keras.callbacks.ModelCheckpoint(filepath=CKPT_DIR + 'compnet_order_' + str(idx),\n",
    "                                                    monitor='val_loss',\n",
    "                                                    verbose=False,\n",
    "                                                    save_best_only=True),\n",
    "                 tf.keras.callbacks.TensorBoard(log_dir=LOG_DIR,\n",
    "                                                histogram_freq=1)]\n",
    "    \n",
    "    order_models[idx].fit(x=ilsvrc2012_train_order[idx],\n",
    "                          epochs=3,\n",
    "                          verbose=True,\n",
    "                          callbacks=callbacks,\n",
    "                          validation_data=ilsvrc2012_val_order[idx],\n",
    "                          shuffle=True,\n",
    "                          validation_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Species layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ilsvrc2012_train_species = [process_and_augment(ilsvrc2012_train_raw, batch_size=128, synset_level=ILSVRC2012_SPECIES_LABEL_LEVEL, hypernym=ilsvrc2012_decode(category, ILSVRC2012_ORDER_LABEL_LEVEL), is_train=True, num_rnd_crops=5, shuffle_buffer_size=10000, num_epochs=1) for category in range(ILSVRC2012_NUM_LABELS_ORDER_LAYER)]\n",
    "ilsvrc2012_val_species = [process_and_augment(ilsvrc2012_val_raw, batch_size=128, synset_level=ILSVRC2012_SPECIES_LABEL_LEVEL, hypernym=ilsvrc2012_decode(category, ILSVRC2012_ORDER_LABEL_LEVEL), is_train=True, num_rnd_crops=5, shuffle_buffer_size=10000, num_epochs=1) for category in range(ILSVRC2012_NUM_LABELS_ORDER_LAYER)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(16, ILSVRC2012_NUM_LABELS_ORDER_LAYER):    \n",
    "    # EarlyStopping: Stop training early if no significant improvement in the monitored quantity is\n",
    "    #     observed for at least `patience` epochs\n",
    "    # LearningRateScheduler: Dynamically adapt the learning rate depending on the training epoch to\n",
    "    #     facilitate accelerated learning during the first few epochs\n",
    "    # ModelCheckpoint: Save the model after each epoch (if `save_best_only` is set to True, only keep\n",
    "    #     the best model with regard to the monitored quantity)\n",
    "    # TensorBoard: Enable TensorBoard visualization\n",
    "    callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                  min_delta=0.01,\n",
    "                                                  patience=3),\n",
    "                 tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-03 if epoch < 2 else (1e-04 if epoch < 4 else 1e-05)),\n",
    "                 tf.keras.callbacks.ModelCheckpoint(filepath=CKPT_DIR + 'compnet_species_' + str(idx),\n",
    "                                                    monitor='val_loss',\n",
    "                                                    verbose=False,\n",
    "                                                    save_best_only=True),\n",
    "                 tf.keras.callbacks.TensorBoard(log_dir=LOG_DIR,\n",
    "                                                histogram_freq=1)]\n",
    "    \n",
    "    species_models[idx].fit(x=ilsvrc2012_train_species[idx],\n",
    "                            epochs=5,\n",
    "                            initial_epoch=3,\n",
    "                            verbose=True,\n",
    "                            callbacks=callbacks,\n",
    "                            validation_data=ilsvrc2012_val_species[idx],\n",
    "                            shuffle=True,\n",
    "                            validation_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "<a id='compnet_test'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Phylum layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ilsvrc2012_test_phylum = process_and_augment(ilsvrc2012_test_raw, batch_size=10, synset_level=ILSVRC2012_PHYLUM_LABEL_LEVEL, hypernym=None, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics to watch during the evaluation of the model on the test data set\n",
    "\n",
    "# Use the same metrics as for the training\n",
    "# test_metrics = metrics\n",
    "\n",
    "# Use different metrics than during the training\n",
    "test_metrics = [tf.keras.metrics.CategoricalAccuracy(name='CategoricalAccuracy'),\n",
    "                tf.keras.metrics.TopKCategoricalAccuracy(k=5, name='TopKCategoricalAccuracy'),\n",
    "                tf.keras.metrics.CategoricalCrossentropy(name='CategoricalCrossentropy'),\n",
    "                tf.keras.metrics.AUC(name='AUC')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset all metrics before starting the evaluation\n",
    "for metric in test_metrics:\n",
    "    metric.reset_states()\n",
    "\n",
    "for (imgs, ground_truths) in ilsvrc2012_test_phylum:\n",
    "    # Generate predictions for each image in the current batch\n",
    "    batch_scores = phylum_model.predict(imgs)\n",
    "    \n",
    "    # Since we constructed our test data set in a way that each image in one batch is an augmented\n",
    "    # version of the same base image, we can simply average the individual scores to get the final\n",
    "    # prediction for the respective base image in adherence to (Goodfellow et al., 2013) and\n",
    "    # (Krizhevsky et al., 2012).\n",
    "    prediction = tf.math.reduce_mean(batch_scores, axis=0)\n",
    "    \n",
    "    # Update the metrics w/ the result for the current base image; as all images in one batch\n",
    "    # originate from the same base image (cf. above), the ground truth is hence identical as well.\n",
    "    # Annotation: The `tf.expand_dims` is a workaround for compatibility with\n",
    "    # `tf.keras.metrics.TopKCategoricalAccuracy` since the latter  does not accept one-dimensional\n",
    "    # inputs as of TensorFlow version v2.2.0-rc3.\n",
    "    for metric in test_metrics:\n",
    "        metric.update_state(tf.expand_dims(ground_truths[0], 0), tf.expand_dims(prediction, 0))\n",
    "\n",
    "print('Phylum Model')\n",
    "print()\n",
    "print('==================================================')\n",
    "print()\n",
    "print('Final results:')\n",
    "for metric in test_metrics:\n",
    "    print('{}: {}'.format(metric.name, metric.result().numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ilsvrc2012_test_class = [process_and_augment(ilsvrc2012_test_raw, batch_size=10, synset_level=ILSVRC2012_CLASS_LABEL_LEVEL, hypernym=ilsvrc2012_decode(category, ILSVRC2012_PHYLUM_LABEL_LEVEL), is_train=False) for category in range(ILSVRC2012_NUM_LABELS_PHYLUM_LAYER)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(ILSVRC2012_NUM_LABELS_PHYLUM_LAYER):\n",
    "    # Define metrics to watch during the evaluation of the model on the test data set\n",
    "\n",
    "    # Use the same metrics as for the training\n",
    "    # test_metrics = metrics\n",
    "\n",
    "    # Use different metrics than during the training\n",
    "    test_metrics = [tf.keras.metrics.CategoricalAccuracy(name='CategoricalAccuracy'),\n",
    "                    tf.keras.metrics.TopKCategoricalAccuracy(k=5, name='TopKCategoricalAccuracy'),\n",
    "                    tf.keras.metrics.CategoricalCrossentropy(name='CategoricalCrossentropy'),\n",
    "                    tf.keras.metrics.AUC(name='AUC')]\n",
    "\n",
    "    # Reset all metrics before starting the evaluation\n",
    "    for metric in test_metrics:\n",
    "        metric.reset_states()\n",
    "\n",
    "    for (imgs, ground_truths) in ilsvrc2012_test_class[idx]:\n",
    "        # Generate predictions for each image in the current batch\n",
    "        batch_scores = class_models[idx].predict(imgs)\n",
    "\n",
    "        # Since we constructed our test data set in a way that each image in one batch is an augmented\n",
    "        # version of the same base image, we can simply average the individual scores to get the final\n",
    "        # prediction for the respective base image in adherence to (Goodfellow et al., 2013) and\n",
    "        # (Krizhevsky et al., 2012).\n",
    "        prediction = tf.math.reduce_mean(batch_scores, axis=0)\n",
    "\n",
    "        # Update the metrics w/ the result for the current base image; as all images in one batch\n",
    "        # originate from the same base image (cf. above), the ground truth is hence identical as well.\n",
    "        # Annotation: The `tf.expand_dims` is a workaround for compatibility with\n",
    "        # `tf.keras.metrics.TopKCategoricalAccuracy` since the latter  does not accept one-dimensional\n",
    "        # inputs as of TensorFlow version v2.2.0-rc3.\n",
    "        for metric in test_metrics:\n",
    "            metric.update_state(tf.expand_dims(ground_truths[0], 0), tf.expand_dims(prediction, 0))\n",
    "\n",
    "    print('Class Model #{}'.format(ilsvrc2012_decode(idx, ILSVRC2012_PHYLUM_LABEL_LEVEL)))\n",
    "    print()\n",
    "    print('==================================================')\n",
    "    print()\n",
    "    print('Final results:')\n",
    "    for metric in test_metrics:\n",
    "        print('{}: {}'.format(metric.name, metric.result().numpy()))\n",
    "    print()\n",
    "    print('====================================================================================================')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Order layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ilsvrc2012_test_order = [process_and_augment(ilsvrc2012_test_raw, batch_size=10, synset_level=ILSVRC2012_ORDER_LABEL_LEVEL, hypernym=ilsvrc2012_decode(category, ILSVRC2012_CLASS_LABEL_LEVEL), is_train=False) for category in range(ILSVRC2012_NUM_LABELS_CLASS_LAYER)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(ILSVRC2012_NUM_LABELS_CLASS_LAYER):\n",
    "    # Define metrics to watch during the evaluation of the model on the test data set\n",
    "\n",
    "    # Use the same metrics as for the training\n",
    "    # test_metrics = metrics\n",
    "\n",
    "    # Use different metrics than during the training\n",
    "    test_metrics = [tf.keras.metrics.CategoricalAccuracy(name='CategoricalAccuracy'),\n",
    "                    tf.keras.metrics.TopKCategoricalAccuracy(k=5, name='TopKCategoricalAccuracy'),\n",
    "                    tf.keras.metrics.CategoricalCrossentropy(name='CategoricalCrossentropy'),\n",
    "                    tf.keras.metrics.AUC(name='AUC')]\n",
    "\n",
    "    # Reset all metrics before starting the evaluation\n",
    "    for metric in test_metrics:\n",
    "        metric.reset_states()\n",
    "\n",
    "    for (imgs, ground_truths) in ilsvrc2012_test_order[idx]:\n",
    "        # Generate predictions for each image in the current batch\n",
    "        batch_scores = order_models[idx].predict(imgs)\n",
    "\n",
    "        # Since we constructed our test data set in a way that each image in one batch is an augmented\n",
    "        # version of the same base image, we can simply average the individual scores to get the final\n",
    "        # prediction for the respective base image in adherence to (Goodfellow et al., 2013) and\n",
    "        # (Krizhevsky et al., 2012).\n",
    "        prediction = tf.math.reduce_mean(batch_scores, axis=0)\n",
    "\n",
    "        # Update the metrics w/ the result for the current base image; as all images in one batch\n",
    "        # originate from the same base image (cf. above), the ground truth is hence identical as well.\n",
    "        # Annotation: The `tf.expand_dims` is a workaround for compatibility with\n",
    "        # `tf.keras.metrics.TopKCategoricalAccuracy` since the latter  does not accept one-dimensional\n",
    "        # inputs as of TensorFlow version v2.2.0-rc3.\n",
    "        for metric in test_metrics:\n",
    "            metric.update_state(tf.expand_dims(ground_truths[0], 0), tf.expand_dims(prediction, 0))\n",
    "\n",
    "    print('Order Model #{}'.format(ilsvrc2012_decode(idx, ILSVRC2012_CLASS_LABEL_LEVEL)))\n",
    "    print()\n",
    "    print('==================================================')\n",
    "    print()\n",
    "    print('Final results:')\n",
    "    for metric in test_metrics:\n",
    "        print('{}: {}'.format(metric.name, metric.result().numpy()))\n",
    "    print()\n",
    "    print('====================================================================================================')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Species layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ilsvrc2012_test_species = [process_and_augment(ilsvrc2012_test_raw, batch_size=10, synset_level=ILSVRC2012_SPECIES_LABEL_LEVEL, hypernym=ilsvrc2012_decode(category, ILSVRC2012_ORDER_LABEL_LEVEL), is_train=False) for category in range(ILSVRC2012_NUM_LABELS_ORDER_LAYER)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(ILSVRC2012_NUM_LABELS_ORDER_LAYER):\n",
    "    # Define metrics to watch during the evaluation of the model on the test data set\n",
    "\n",
    "    # Use the same metrics as for the training\n",
    "    # test_metrics = metrics\n",
    "\n",
    "    # Use different metrics than during the training\n",
    "    test_metrics = [tf.keras.metrics.CategoricalAccuracy(name='CategoricalAccuracy'),\n",
    "                    tf.keras.metrics.TopKCategoricalAccuracy(k=5, name='TopKCategoricalAccuracy'),\n",
    "                    tf.keras.metrics.CategoricalCrossentropy(name='CategoricalCrossentropy'),\n",
    "                    tf.keras.metrics.AUC(name='AUC')]\n",
    "\n",
    "    # Reset all metrics before starting the evaluation\n",
    "    for metric in test_metrics:\n",
    "        metric.reset_states()\n",
    "\n",
    "    for (imgs, ground_truths) in ilsvrc2012_test_species[idx]:\n",
    "        # Generate predictions for each image in the current batch\n",
    "        batch_scores = species_models[idx].predict(imgs)\n",
    "\n",
    "        # Since we constructed our test data set in a way that each image in one batch is an augmented\n",
    "        # version of the same base image, we can simply average the individual scores to get the final\n",
    "        # prediction for the respective base image in adherence to (Goodfellow et al., 2013) and\n",
    "        # (Krizhevsky et al., 2012).\n",
    "        prediction = tf.math.reduce_mean(batch_scores, axis=0)\n",
    "\n",
    "        # Update the metrics w/ the result for the current base image; as all images in one batch\n",
    "        # originate from the same base image (cf. above), the ground truth is hence identical as well.\n",
    "        # Annotation: The `tf.expand_dims` is a workaround for compatibility with\n",
    "        # `tf.keras.metrics.TopKCategoricalAccuracy` since the latter  does not accept one-dimensional\n",
    "        # inputs as of TensorFlow version v2.2.0-rc3.\n",
    "        for metric in test_metrics:\n",
    "            metric.update_state(tf.expand_dims(ground_truths[0], 0), tf.expand_dims(prediction, 0))\n",
    "\n",
    "    print('Species Model #{}'.format(ilsvrc2012_decode(idx, ILSVRC2012_ORDER_LABEL_LEVEL)))\n",
    "    print()\n",
    "    print('==================================================')\n",
    "    print()\n",
    "    print('Final results:')\n",
    "    for metric in test_metrics:\n",
    "        print('{}: {}'.format(metric.name, metric.result().numpy()))\n",
    "    print()\n",
    "    print('====================================================================================================')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Composed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ilsvrc2012_test_composed = process_and_augment(ilsvrc2012_test_raw, batch_size=10, synset_level=ILSVRC2012_SPECIES_LABEL_LEVEL, hypernym=None, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics to watch during the evaluation of the model on the test data set\n",
    "\n",
    "# Use the same metrics as for the training\n",
    "# test_metrics = metrics\n",
    "\n",
    "# Use different metrics than during the training\n",
    "test_metrics = [tf.keras.metrics.CategoricalAccuracy(name='CategoricalAccuracy'),\n",
    "                tf.keras.metrics.TopKCategoricalAccuracy(k=5, name='TopKCategoricalAccuracy'),\n",
    "                tf.keras.metrics.CategoricalCrossentropy(name='CategoricalCrossentropy'),\n",
    "                tf.keras.metrics.AUC(name='AUC')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset all metrics before starting the evaluation\n",
    "for metric in test_metrics:\n",
    "    metric.reset_states()\n",
    "    \n",
    "# Initialize additional custom metrics to watch during the evaluation\n",
    "\n",
    "# Overall label distribution (predicted and ground truth)\n",
    "dist_ground_truth = [0] * ILSVRC2012_NUM_LABELS_SPECIES_LAYER\n",
    "dist_predicted = [0] * ILSVRC2012_NUM_LABELS_SPECIES_LAYER\n",
    "\n",
    "# Predicted label distribution for each taxonomic category\n",
    "dist_predicted_phylum = [[0] * ILSVRC2012_NUM_LABELS_PHYLUM_LAYER for _ in range(ILSVRC2012_NUM_LABELS_PHYLUM_LAYER)]\n",
    "dist_predicted_class = [[0] * ILSVRC2012_NUM_LABELS_CLASS_LAYER for _ in range(ILSVRC2012_NUM_LABELS_CLASS_LAYER)]\n",
    "dist_predicted_order = [[0] * ILSVRC2012_NUM_LABELS_ORDER_LAYER for _ in range(ILSVRC2012_NUM_LABELS_ORDER_LAYER)]\n",
    "dist_predicted_species = [[0] * ILSVRC2012_NUM_LABELS_SPECIES_LAYER for _ in range(ILSVRC2012_NUM_LABELS_SPECIES_LAYER)]\n",
    "\n",
    "# Fine label distribution for each coarse category (predicted and ground truth)\n",
    "dist_ground_truth_phylum_class = [[0] * ILSVRC2012_NUM_LABELS_CLASS_LAYER for _ in range(ILSVRC2012_NUM_LABELS_PHYLUM_LAYER)]\n",
    "dist_predicted_phylum_class = [[0] * ILSVRC2012_NUM_LABELS_CLASS_LAYER for _ in range(ILSVRC2012_NUM_LABELS_PHYLUM_LAYER)]\n",
    "dist_ground_truth_phylum_order = [[0] * ILSVRC2012_NUM_LABELS_ORDER_LAYER for _ in range(ILSVRC2012_NUM_LABELS_PHYLUM_LAYER)]\n",
    "dist_predicted_phylum_order = [[0] * ILSVRC2012_NUM_LABELS_ORDER_LAYER for _ in range(ILSVRC2012_NUM_LABELS_PHYLUM_LAYER)]\n",
    "dist_ground_truth_phylum_species = [[0] * ILSVRC2012_NUM_LABELS_SPECIES_LAYER for _ in range(ILSVRC2012_NUM_LABELS_PHYLUM_LAYER)]\n",
    "dist_predicted_phylum_species = [[0] * ILSVRC2012_NUM_LABELS_SPECIES_LAYER for _ in range(ILSVRC2012_NUM_LABELS_PHYLUM_LAYER)]\n",
    "dist_ground_truth_class_order = [[0] * ILSVRC2012_NUM_LABELS_ORDER_LAYER for _ in range(ILSVRC2012_NUM_LABELS_CLASS_LAYER)]\n",
    "dist_predicted_class_order = [[0] * ILSVRC2012_NUM_LABELS_ORDER_LAYER for _ in range(ILSVRC2012_NUM_LABELS_CLASS_LAYER)]\n",
    "dist_ground_truth_class_species = [[0] * ILSVRC2012_NUM_LABELS_SPECIES_LAYER for _ in range(ILSVRC2012_NUM_LABELS_CLASS_LAYER)]\n",
    "dist_predicted_class_species = [[0] * ILSVRC2012_NUM_LABELS_SPECIES_LAYER for _ in range(ILSVRC2012_NUM_LABELS_CLASS_LAYER)]\n",
    "dist_ground_truth_order_species = [[0] * ILSVRC2012_NUM_LABELS_SPECIES_LAYER for _ in range(ILSVRC2012_NUM_LABELS_ORDER_LAYER)]\n",
    "dist_predicted_order_species = [[0] * ILSVRC2012_NUM_LABELS_SPECIES_LAYER for _ in range(ILSVRC2012_NUM_LABELS_ORDER_LAYER)]\n",
    "\n",
    "# Semantic distance between the predicted category and the ground truth in accordance to\n",
    "# (Fergus et al., 2010)\n",
    "semantic_distance = 0.0\n",
    "\n",
    "# Uncertainty metrics in accordance to (Ovadia et. al, 2019)\n",
    "confidence = []\n",
    "cat_acc = []\n",
    "neg_log_likelihood = []\n",
    "brier_score = []\n",
    "pred_entropy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (imgs, ground_truths) in ilsvrc2012_test_composed:\n",
    "    # Generate predictions for each image in the current batch\n",
    "    batch_scores_phylum = phylum_model.predict(imgs)\n",
    "    \n",
    "    # Since we constructed our test data set in a way that each image in one batch is an augmented\n",
    "    # version of the same base image, we can simply average the individual scores to get the final\n",
    "    # prediction for the respective base image in adherence to (Goodfellow et al., 2013) and\n",
    "    # (Krizhevsky et al., 2012).\n",
    "    prediction_phylum = tf.math.reduce_mean(batch_scores_phylum, axis=0)\n",
    "    \n",
    "    # Route the current batch to the sub-module predcited by the phylum model and generate the\n",
    "    # predictions for the respective class category labels\n",
    "    batch_scores_class = class_models[tf.math.argmax(prediction_phylum)].predict(imgs)\n",
    "    \n",
    "    # Average the scores for the individual images in the batch as described above\n",
    "    prediction_class = tf.math.reduce_mean(batch_scores_class, axis=0)\n",
    "    \n",
    "    # Route the current batch to the sub-module predcited by the class model and generate the\n",
    "    # predictions for the respective order category labels\n",
    "    batch_scores_order = order_models[tf.math.argmax(prediction_class)].predict(imgs)\n",
    "    \n",
    "    # Average the scores for the individual images in the batch as described above\n",
    "    prediction_order = tf.math.reduce_mean(batch_scores_order, axis=0)\n",
    "    \n",
    "    # Route the current batch to the sub-module predcited by the order model and generate the\n",
    "    # predictions for the respective species category labels\n",
    "    batch_scores_species = species_models[tf.math.argmax(prediction_order)].predict(imgs)\n",
    "    \n",
    "    # Average the scores for the individual images in the batch as described above\n",
    "    prediction_species = tf.math.reduce_mean(batch_scores_species, axis=0)\n",
    "    \n",
    "    # Update the metrics w/ the result for the current base image; as all images in one batch\n",
    "    # originate from the same base image (cf. above), the ground truth is hence identical as well.\n",
    "    # Annotation: The `tf.expand_dims` is a workaround for compatibility with\n",
    "    # `tf.keras.metrics.TopKCategoricalAccuracy` since the latter  does not accept one-dimensional\n",
    "    # inputs as of TensorFlow version v2.2.0-rc3.\n",
    "    for metric in test_metrics:\n",
    "        metric.update_state(tf.expand_dims(ground_truths[0], 0), tf.expand_dims(prediction_species, 0))\n",
    "        \n",
    "    # Update custom metrics w/ the result for the current base image; cf. above concerning the\n",
    "    # ground truth for each batch\n",
    "    \n",
    "    ground_truth = ground_truths[0]\n",
    "    ground_truth_species = tf.math.argmax(ground_truth).numpy()\n",
    "    ground_truth_species_decoded = ilsvrc2012_decode(ground_truth_species, ILSVRC2012_SPECIES_LABEL_LEVEL)\n",
    "    \n",
    "    ground_truth_phylum = ilsvrc2012_resolve_hypernym(ground_truth_species, ILSVRC2012_PHYLUM_LABEL_LEVEL, encoded=True)\n",
    "    ground_truth_class = ilsvrc2012_resolve_hypernym(ground_truth_species, ILSVRC2012_CLASS_LABEL_LEVEL, encoded=True)\n",
    "    ground_truth_order = ilsvrc2012_resolve_hypernym(ground_truth_species, ILSVRC2012_ORDER_LABEL_LEVEL, encoded=True)\n",
    "\n",
    "    prediction = prediction_species\n",
    "    prediction_species = tf.math.argmax(prediction).numpy()\n",
    "    prediction_species_decoded = ilsvrc2012_decode(prediction_species, ILSVRC2012_SPECIES_LABEL_LEVEL)\n",
    "    \n",
    "    prediction_phylum = tf.math.argmax(prediction_phylum).numpy()\n",
    "    prediction_class = tf.math.argmax(prediction_class).numpy()\n",
    "    prediction_order = tf.math.argmax(prediction_order).numpy()\n",
    "    \n",
    "    dist_ground_truth[ground_truth_species] += 1\n",
    "    dist_predicted[prediction_species] += 1\n",
    "\n",
    "    dist_predicted_phylum[ground_truth_phylum][prediction_phylum] += 1\n",
    "    dist_predicted_class[ground_truth_class][prediction_class] += 1\n",
    "    dist_predicted_order[ground_truth_order][prediction_order] += 1\n",
    "    dist_predicted_species[ground_truth_species][prediction_species] += 1\n",
    "\n",
    "    dist_ground_truth_phylum_class[ground_truth_phylum][prediction_class] += 1\n",
    "    dist_predicted_phylum_class[ground_truth_phylum][prediction_class] += 1\n",
    "    dist_ground_truth_phylum_order[ground_truth_phylum][prediction_order] += 1\n",
    "    dist_predicted_phylum_order[ground_truth_phylum][prediction_order] += 1\n",
    "    dist_ground_truth_phylum_species[ground_truth_phylum][prediction_species] += 1\n",
    "    dist_predicted_phylum_species[ground_truth_phylum][prediction_species] += 1\n",
    "    dist_ground_truth_class_order[ground_truth_class][prediction_order] += 1\n",
    "    dist_predicted_class_order[ground_truth_class][prediction_order] += 1\n",
    "    dist_ground_truth_class_species[ground_truth_class][prediction_species] += 1\n",
    "    dist_predicted_class_species[ground_truth_class][prediction_species] += 1\n",
    "    dist_ground_truth_order_species[ground_truth_order][prediction_species] += 1\n",
    "    dist_predicted_order_species[ground_truth_order][prediction_species] += 1\n",
    "    \n",
    "    semantic_distance += ILSVRC2012_SYNSET_MAP.semantic_distance(\n",
    "        ground_truth_species_decoded,\n",
    "        prediction_species_decoded\n",
    "    )\n",
    "\n",
    "    confidence.append(\n",
    "        prediction[prediction_species])\n",
    "        \n",
    "    cat_acc.append(\n",
    "        tf.dtypes.cast(tf.math.equal(ground_truth_species, prediction_species), tf.dtypes.float32))\n",
    "\n",
    "    neg_log_likelihood.append(\n",
    "        -tf.math.log(prediction[ground_truth_species]))\n",
    "\n",
    "    brier_score.append(\n",
    "        tf.math.reduce_sum((prediction - ground_truth) ** 2))\n",
    "\n",
    "    pred_entropy.append(\n",
    "        -tf.math.reduce_sum(tf.map_fn(lambda p: p * tf.math.log(p), prediction)))\n",
    "\n",
    "print('Benchmark')\n",
    "print()\n",
    "print('==================================================')\n",
    "print()\n",
    "print('Final results:')\n",
    "for metric in test_metrics:\n",
    "    print('{}: {}'.format(metric.name, metric.result().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the results\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_COMPNET + 'dist_ground_truth.data',\n",
    "    tf.io.serialize_tensor(dist_ground_truth))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_COMPNET + 'dist_predicted.data',\n",
    "    tf.io.serialize_tensor(dist_predicted))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_COMPNET + 'dist_predicted_phylum.data',\n",
    "    tf.io.serialize_tensor(dist_predicted_phylum))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_COMPNET + 'dist_predicted_class.data',\n",
    "    tf.io.serialize_tensor(dist_predicted_class))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_COMPNET + 'dist_predicted_order.data',\n",
    "    tf.io.serialize_tensor(dist_predicted_order))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_COMPNET + 'dist_predicted_species.data',\n",
    "    tf.io.serialize_tensor(dist_predicted_species))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_COMPNET + 'dist_ground_truth_phylum_class.data',\n",
    "    tf.io.serialize_tensor(dist_ground_truth_phylum_class))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_COMPNET + 'dist_predicted_phylum_class.data',\n",
    "    tf.io.serialize_tensor(dist_predicted_phylum_class))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_COMPNET + 'dist_ground_truth_phylum_order.data',\n",
    "    tf.io.serialize_tensor(dist_ground_truth_phylum_order))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_COMPNET + 'dist_predicted_phylum_order.data',\n",
    "    tf.io.serialize_tensor(dist_predicted_phylum_order))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_COMPNET + 'dist_ground_truth_phylum_species.data',\n",
    "    tf.io.serialize_tensor(dist_ground_truth_phylum_species))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_COMPNET + 'dist_predicted_phylum_species.data',\n",
    "    tf.io.serialize_tensor(dist_predicted_phylum_species))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_COMPNET + 'dist_ground_truth_class_order.data',\n",
    "    tf.io.serialize_tensor(dist_ground_truth_class_order))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_COMPNET + 'dist_predicted_class_order.data',\n",
    "    tf.io.serialize_tensor(dist_predicted_class_order))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_COMPNET + 'dist_ground_truth_class_species.data',\n",
    "    tf.io.serialize_tensor(dist_ground_truth_class_species))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_COMPNET + 'dist_predicted_class_species.data',\n",
    "    tf.io.serialize_tensor(dist_predicted_class_species))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_COMPNET + 'dist_ground_truth_order_species.data',\n",
    "    tf.io.serialize_tensor(dist_ground_truth_order_species))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_COMPNET + 'dist_predicted_order_species.data',\n",
    "    tf.io.serialize_tensor(dist_predicted_order_species))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_COMPNET + 'semantic_distance.data',\n",
    "    tf.io.serialize_tensor(semantic_distance))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_COMPNET + 'confidence.data',\n",
    "    tf.io.serialize_tensor(confidence))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_COMPNET + 'cat_acc.data',\n",
    "    tf.io.serialize_tensor(cat_acc))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_COMPNET + 'neg_log_likelihood.data',\n",
    "    tf.io.serialize_tensor(neg_log_likelihood))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_COMPNET + 'brier_score.data',\n",
    "    tf.io.serialize_tensor(brier_score))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_COMPNET + 'pred_entropy.data',\n",
    "    tf.io.serialize_tensor(pred_entropy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the results\n",
    "\n",
    "dist_ground_truth = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_COMPNET + 'dist_ground_truth.data'),\n",
    "        tf.dtypes.int32)\n",
    "\n",
    "dist_predicted = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_COMPNET + 'dist_predicted.data'),\n",
    "        tf.dtypes.int32)\n",
    "\n",
    "dist_predicted_phylum = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_COMPNET + 'dist_predicted_phylum.data'),\n",
    "        tf.dtypes.int32)\n",
    "\n",
    "dist_predicted_class = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_COMPNET + 'dist_predicted_class.data'),\n",
    "        tf.dtypes.int32)\n",
    "\n",
    "dist_predicted_order = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_COMPNET + 'dist_predicted_order.data'),\n",
    "        tf.dtypes.int32)\n",
    "\n",
    "dist_predicted_species = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_COMPNET + 'dist_predicted_species.data'),\n",
    "        tf.dtypes.int32)\n",
    "\n",
    "dist_ground_truth_phylum_class = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_COMPNET + 'dist_ground_truth_phylum_class.data'),\n",
    "        tf.dtypes.int32)\n",
    "\n",
    "dist_predicted_phylum_class = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_COMPNET + 'dist_predicted_phylum_class.data'),\n",
    "        tf.dtypes.int32)\n",
    "\n",
    "dist_ground_truth_phylum_order = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_COMPNET + 'dist_ground_truth_phylum_order.data'),\n",
    "        tf.dtypes.int32)\n",
    "\n",
    "dist_predicted_phylum_order = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_COMPNET + 'dist_predicted_phylum_order.data'),\n",
    "        tf.dtypes.int32)\n",
    "\n",
    "dist_ground_truth_phylum_species = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_COMPNET + 'dist_ground_truth_phylum_species.data'),\n",
    "        tf.dtypes.int32)\n",
    "\n",
    "dist_predicted_phylum_species = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_COMPNET + 'dist_predicted_phylum_species.data'),\n",
    "        tf.dtypes.int32)\n",
    "\n",
    "dist_ground_truth_class_order = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_COMPNET + 'dist_ground_truth_class_order.data'),\n",
    "        tf.dtypes.int32)\n",
    "\n",
    "dist_predicted_class_order = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_COMPNET + 'dist_predicted_class_order.data'),\n",
    "        tf.dtypes.int32)\n",
    "\n",
    "dist_ground_truth_class_species = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_COMPNET + 'dist_ground_truth_class_species.data'),\n",
    "        tf.dtypes.int32)\n",
    "\n",
    "dist_predicted_class_species = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_COMPNET + 'dist_predicted_class_species.data'),\n",
    "        tf.dtypes.int32)\n",
    "\n",
    "dist_ground_truth_order_species = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_COMPNET + 'dist_ground_truth_order_species.data'),\n",
    "        tf.dtypes.int32)\n",
    "\n",
    "dist_predicted_order_species = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_COMPNET + 'dist_predicted_order_species.data'),\n",
    "        tf.dtypes.int32)\n",
    "\n",
    "semantic_distance = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_COMPNET + 'semantic_distance.data'),\n",
    "        tf.dtypes.float32)\n",
    "\n",
    "confidence = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_COMPNET + 'confidence.data'),\n",
    "        tf.dtypes.float32)\n",
    "\n",
    "cat_acc = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_COMPNET + 'cat_acc.data'),\n",
    "        tf.dtypes.float32)\n",
    "\n",
    "neg_log_likelihood = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_COMPNET + 'neg_log_likelihood.data'),\n",
    "        tf.dtypes.float32)\n",
    "\n",
    "brier_score = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_COMPNET + 'brier_score.data'),\n",
    "        tf.dtypes.float32)\n",
    "\n",
    "pred_entropy = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_COMPNET + 'pred_entropy.data'),\n",
    "        tf.dtypes.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 5))\n",
    "titles = ['Predicted', 'Ground Truth']\n",
    "\n",
    "for idx, dist in enumerate([dist_predicted, dist_ground_truth]):\n",
    "    # Normalize the distribution\n",
    "    dist = list(map(lambda entry: entry / sum(dist), dist)) \n",
    "                \n",
    "    # Plot the distribution\n",
    "    ax[idx].bar(range(1, len(dist) + 1), dist, width=1)\n",
    "    ax[idx].set_title(titles[idx])\n",
    "    ax[idx].set_xticks(range(0, ILSVRC2012_NUM_LABELS_SPECIES_LAYER, 25))\n",
    "    ax[idx].set_ylim([0, 0.033])\n",
    "    ax[idx].set_xlabel('Labels')\n",
    "    ax[idx].set_ylabel('Share')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=(20, 15))\n",
    "\n",
    "for label in range(ILSVRC2012_NUM_LABELS_PHYLUM_LAYER):\n",
    "    # Normalize the distribution\n",
    "    dist = list(map(\n",
    "        lambda entry: entry / sum(dist_predicted_phylum[label]), dist_predicted_phylum[label])) \n",
    "\n",
    "    # Plot the distribution\n",
    "    ax[label].bar(range(0, len(dist)), dist, width=1)\n",
    "    ax[label].set_title(\n",
    "        'Predicted Distribution for #{}'.format(ilsvrc2012_decode(label, ILSVRC2012_PHYLUM_LABEL_LEVEL))\n",
    "    )\n",
    "    ax[label].set_xticks(range(0, ILSVRC2012_NUM_LABELS_PHYLUM_LAYER, 1))\n",
    "    ax[label].set_xlabel('Labels')\n",
    "    ax[label].set_ylabel('Share')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(11, 1, figsize=(20, 165)\n",
    "\n",
    "for label in range(ILSVRC2012_NUM_LABELS_CLASS_LAYER):\n",
    "    # Normalize the distribution\n",
    "    dist = list(map(\n",
    "        lambda entry: entry / sum(dist_predicted_class[label]), dist_predicted_class[label])) \n",
    "\n",
    "    # Plot the distribution\n",
    "    ax[label].bar(range(0, len(dist)), dist, width=1)\n",
    "    ax[label].set_title(\n",
    "        'Predicted Distribution for #{}'.format(ilsvrc2012_decode(label, ILSVRC2012_CLASS_LABEL_LEVEL))\n",
    "    )\n",
    "    ax[label].set_xticks(range(0, ILSVRC2012_NUM_LABELS_CLASS_LAYER, 1))\n",
    "    ax[label].set_xlabel('Labels')\n",
    "    ax[label].set_ylabel('Share')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(12, 4, figsize=(20, 180))\n",
    "\n",
    "for label in range(ILSVRC2012_NUM_LABELS_ORDER_LAYER):\n",
    "    row = int(label / 4)\n",
    "    col = int(label % 4)\n",
    "    \n",
    "    # Normalize the distribution\n",
    "    dist = list(map(\n",
    "        lambda entry: entry / sum(dist_predicted_order[label]), dist_predicted_order[label])) \n",
    "\n",
    "    # Plot the distribution\n",
    "    ax[row][col].bar(range(0, len(dist)), dist, width=1)\n",
    "    ax[row][col].set_title(\n",
    "        'Predicted Distribution for #{}'.format(ilsvrc2012_decode(label, ILSVRC2012_ORDER_LABEL_LEVEL))\n",
    "    )\n",
    "    ax[row][col].set_xticks(range(0, ILSVRC2012_NUM_LABELS_ORDER_LAYER, 4))\n",
    "    ax[row][col].set_xlabel('Labels')\n",
    "    ax[row][col].set_ylabel('Share')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(95, 4, figsize=(20, 1425))\n",
    "\n",
    "for label in range(ILSVRC2012_NUM_LABELS_SPECIES_LAYER):\n",
    "    row = int(label / 4)\n",
    "    col = int(label % 4)\n",
    "    \n",
    "    # Normalize the distribution\n",
    "    dist = list(map(\n",
    "        lambda entry: entry / sum(dist_predicted_species[label]), dist_predicted_species[label])) \n",
    "\n",
    "    # Plot the distribution\n",
    "    ax[row][col].bar(range(0, len(dist)), dist, width=1)\n",
    "    ax[row][col].set_title(\n",
    "        'Predicted Distribution for #{}'.format(ilsvrc2012_decode(label, ILSVRC2012_SPECIES_LABEL_LEVEL))\n",
    "    )\n",
    "    ax[row][col].set_xticks(range(0, ILSVRC2012_NUM_LABELS_SPECIES_LAYER, 20))\n",
    "    ax[row][col].set_xlabel('Labels')\n",
    "    ax[row][col].set_ylabel('Share')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(20, 30))\n",
    "\n",
    "for label in range(ILSVRC2012_NUM_LABELS_PHYLUM_LAYER):\n",
    "    titles = ['Predicted Distribution for #{}'.format(ilsvrc2012_decode(label, ILSVRC2012_PHYLUM_LABEL_LEVEL)),\n",
    "          'Ground Truth Distribution for #{}'.format(ilsvrc2012_decode(label, ILSVRC2012_PHYLUM_LABEL_LEVEL))]\n",
    "\n",
    "    for idx, dist in enumerate([dist_predicted_phylum_class, dist_ground_truth_phylum_class]):\n",
    "        # Normalize the distribution\n",
    "        dist = list(map(lambda entry: entry / sum(dist[label]), dist[label])) \n",
    "                    \n",
    "        # Plot the distribution\n",
    "        ax[label][idx].bar(range(1, len(dist) + 1), dist, width=1)\n",
    "        ax[label][idx].set_title(titles[idx])\n",
    "        ax[label][idx].set_xticks(range(0, ILSVRC2012_NUM_LABELS_CLASS_LAYER, 1))\n",
    "        ax[label][idx].set_ylim([0, 0.33])\n",
    "        ax[label][idx].set_xlabel('Labels')\n",
    "        ax[label][idx].set_ylabel('Share')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(20, 30))\n",
    "\n",
    "for label in range(ILSVRC2012_NUM_LABELS_PHYLUM_LAYER):\n",
    "    titles = ['Predicted Distribution for #{}'.format(ilsvrc2012_decode(label, ILSVRC2012_PHYLUM_LABEL_LEVEL)),\n",
    "          'Ground Truth Distribution for #{}'.format(ilsvrc2012_decode(label, ILSVRC2012_PHYLUM_LABEL_LEVEL))]\n",
    "\n",
    "    for idx, dist in enumerate([dist_predicted_phylum_order, dist_ground_truth_phylum_order]):\n",
    "        # Normalize the distribution\n",
    "        dist = list(map(lambda entry: entry / sum(dist[label]), dist[label])) \n",
    "                    \n",
    "        # Plot the distribution\n",
    "        ax[label][idx].bar(range(1, len(dist) + 1), dist, width=1)\n",
    "        ax[label][idx].set_title(titles[idx])\n",
    "        ax[label][idx].set_xticks(range(0, ILSVRC2012_NUM_LABELS_ORDER_LAYER, 4))\n",
    "        ax[label][idx].set_ylim([0, 0.01])\n",
    "        ax[label][idx].set_xlabel('Labels')\n",
    "        ax[label][idx].set_ylabel('Share')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(20, 30))\n",
    "\n",
    "for label in range(ILSVRC2012_NUM_LABELS_PHYLUM_LAYER):\n",
    "    titles = ['Predicted Distribution for #{}'.format(ilsvrc2012_decode(label, ILSVRC2012_PHYLUM_LABEL_LEVEL)),\n",
    "          'Ground Truth Distribution for #{}'.format(ilsvrc2012_decode(label, ILSVRC2012_PHYLUM_LABEL_LEVEL))]\n",
    "\n",
    "    for idx, dist in enumerate([dist_predicted_phylum_species, dist_ground_truth_phylum_species]):\n",
    "        # Normalize the distribution\n",
    "        dist = list(map(lambda entry: entry / sum(dist[label]), dist[label])) \n",
    "                    \n",
    "        # Plot the distribution\n",
    "        ax[label][idx].bar(range(1, len(dist) + 1), dist, width=1)\n",
    "        ax[label][idx].set_title(titles[idx])\n",
    "        ax[label][idx].set_xticks(range(0, ILSVRC2012_NUM_LABELS_SPECIES_LAYER, 20))\n",
    "        ax[label][idx].set_ylim([0, 0.033])\n",
    "        ax[label][idx].set_xlabel('Labels')\n",
    "        ax[label][idx].set_ylabel('Share')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(11, 2, figsize=(20, 165))\n",
    "\n",
    "for label in range(ILSVRC2012_NUM_LABELS_CLASS_LAYER):\n",
    "    titles = ['Predicted Distribution for #{}'.format(ilsvrc2012_decode(label, ILSVRC2012_CLASS_LABEL_LEVEL)),\n",
    "          'Ground Truth Distribution for #{}'.format(ilsvrc2012_decode(label, ILSVRC2012_CLASS_LABEL_LEVEL))]\n",
    "\n",
    "    for idx, dist in enumerate([dist_predicted_class_order, dist_ground_truth_class_order]):\n",
    "        # Normalize the distribution\n",
    "        dist = list(map(lambda entry: entry / sum(dist[label]), dist[label])) \n",
    "                    \n",
    "        # Plot the distribution\n",
    "        ax[label][idx].bar(range(1, len(dist) + 1), dist, width=1)\n",
    "        ax[label][idx].set_title(titles[idx])\n",
    "        ax[label][idx].set_xticks(range(0, ILSVRC2012_NUM_LABELS_ORDER_LAYER, 4))\n",
    "        ax[label][idx].set_ylim([0, 0.01])\n",
    "        ax[label][idx].set_xlabel('Labels')\n",
    "        ax[label][idx].set_ylabel('Share')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(11, 2, figsize=(20, 165))\n",
    "\n",
    "for label in range(ILSVRC2012_NUM_LABELS_CLASS_LAYER):\n",
    "    titles = ['Predicted Distribution for #{}'.format(ilsvrc2012_decode(label, ILSVRC2012_CLASS_LABEL_LEVEL)),\n",
    "          'Ground Truth Distribution for #{}'.format(ilsvrc2012_decode(label, ILSVRC2012_CLASS_LABEL_LEVEL))]\n",
    "\n",
    "    for idx, dist in enumerate([dist_predicted_class_species, dist_ground_truth_class_species]):\n",
    "        # Normalize the distribution\n",
    "        dist = list(map(lambda entry: entry / sum(dist[label]), dist[label])) \n",
    "                    \n",
    "        # Plot the distribution\n",
    "        ax[label][idx].bar(range(1, len(dist) + 1), dist, width=1)\n",
    "        ax[label][idx].set_title(titles[idx])\n",
    "        ax[label][idx].set_xticks(range(0, ILSVRC2012_NUM_LABELS_SPECIES_LAYER, 20))\n",
    "        ax[label][idx].set_ylim([0, 0.033])\n",
    "        ax[label][idx].set_xlabel('Labels')\n",
    "        ax[label][idx].set_ylabel('Share')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(47, 2, figsize=(20, 40))\n",
    "\n",
    "for label in range(ILSVRC2012_NUM_LABELS_ORDER_LAYER):\n",
    "    titles = ['Predicted Distribution for #{}'.format(ilsvrc2012_decode(label, ILSVRC2012_ORDER_LABEL_LEVEL)),\n",
    "          'Ground Truth Distribution for #{}'.format(ilsvrc2012_decode(label, ILSVRC2012_ORDER_LABEL_LEVEL))]\n",
    "\n",
    "    for idx, dist in enumerate([dist_predicted_order_species, dist_ground_truth_order_species]):\n",
    "        # Normalize the distribution\n",
    "        dist = list(map(lambda entry: entry / sum(dist[label]), dist[label])) \n",
    "                    \n",
    "        # Plot the distribution\n",
    "        ax[label][idx].bar(range(1, len(dist) + 1), dist, width=1)\n",
    "        ax[label][idx].set_title(titles[idx])\n",
    "        ax[label][idx].set_xticks(range(0, ILSVRC2012_NUM_LABELS_SPECIES_LAYER, 20))\n",
    "        ax[label][idx].set_ylim([0, 0.033])\n",
    "        ax[label][idx].set_xlabel('Labels')\n",
    "        ax[label][idx].set_ylabel('Share')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(20, 10))\n",
    "\n",
    "ax.boxplot(cat_acc, sym='')\n",
    "\n",
    "ax.set_title('Categorical accuracy over varying corruption severities')\n",
    "ax.set_ylabel('Accuracy')\n",
    "\n",
    "ax.grid(linestyle='--')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(20, 10))\n",
    "\n",
    "ax.boxplot(brier_score, sym='')\n",
    "\n",
    "ax.set_title('Brier Score over varying corruption severities')\n",
    "ax.set_ylabel('Brier Score')\n",
    "\n",
    "ax.grid(linestyle='--')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(20, 10))\n",
    "\n",
    "ax.hist(confidence[idx], bins=10000, cumulative=-1, histtype='step')\n",
    "ax.set_title('Confidence')\n",
    "ax.set_xlabel('Confidence ' + r'$\\tau$')\n",
    "ax.set_ylabel('Number examples ' + r'$P(x) > \\tau$')\n",
    "#ax.set_xlim([0.002, 1.0])\n",
    "\n",
    "ax.grid(linestyle='--')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(20, 10))\n",
    "\n",
    "ax.hist(neg_log_likelihood[idx], bins=10000, histtype='step')\n",
    "ax.set_title('Negative log likelihood')\n",
    "ax.set_xlabel('Likelihood ' + r'$l$')\n",
    "ax.set_ylabel('Number examples ' + r'$L(x) > l$')\n",
    "#ax.set_xlim([0.202, 1.0])\n",
    "\n",
    "ax.grid(linestyle='--')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(20, 10))\n",
    "\n",
    "ax.hist(pred_entropy[idx], bins=10000, cumulative=-1, histtype='step')\n",
    "ax.set_title('Predictive entropy')\n",
    "ax.set_xlabel('Entropy (Nats)' + r'$h$')\n",
    "ax.set_ylabel('Number examples ' + r'$H(x) > h$')\n",
    "#ax.set_xlim([0.0, 2.5])\n",
    "\n",
    "ax.grid(linestyle='--')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(20, 10))\n",
    "\n",
    "ax.plot(\n",
    "    [val for val in sorted(confidence[idx])],\n",
    "    [val for _, val in sorted(zip(confidence[idx], cat_acc[idx]))])\n",
    "ax.set_title('Confidence vs accuracy')\n",
    "ax.set_xlabel('Confidence ' + r'$\\tau$')\n",
    "ax.set_ylabel('Categorical accuracy on examples ' + r'$P(x) > \\tau$')\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "\n",
    "ax.grid(linestyle='--')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ilsvrc2012_test_modeling_error = process_and_augment(ilsvrc2012_test_raw, batch_size=10, synset_level=ILSVRC2012_SPECIES_LABEL_LEVEL, hypernym=None, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize custom metrics to watch during the evaluation\n",
    "\n",
    "# Categorical crossentropies for each taxonomic category\n",
    "cat_crossentropy_phylum = []\n",
    "cat_crossentropy_class = []\n",
    "cat_crossentropy_order = []\n",
    "cat_crossentropy_species = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (imgs, ground_truths) in ilsvrc2012_test_modeling_error:\n",
    "    # Generate predictions for each image in the current batch\n",
    "    batch_scores_phylum = phylum_model.predict(imgs)\n",
    "    \n",
    "    # Since we constructed our test data set in a way that each image in one batch is an augmented\n",
    "    # version of the same base image, we can simply average the individual scores to get the final\n",
    "    # prediction for the respective base image in adherence to (Goodfellow et al., 2013) and\n",
    "    # (Krizhevsky et al., 2012).\n",
    "    prediction_phylum = tf.math.reduce_mean(batch_scores_phylum, axis=0)\n",
    "    \n",
    "    # Route the current batch to the sub-module predcited by the phylum model and generate the\n",
    "    # predictions for the respective class category labels\n",
    "    batch_scores_class = class_models[tf.math.argmax(prediction_phylum)].predict(imgs)\n",
    "    \n",
    "    # Average the scores for the individual images in the batch as described above\n",
    "    prediction_class = tf.math.reduce_mean(batch_scores_class, axis=0)\n",
    "    \n",
    "    # Route the current batch to the sub-module predcited by the class model and generate the\n",
    "    # predictions for the respective order category labels\n",
    "    batch_scores_order = order_models[tf.math.argmax(prediction_class)].predict(imgs)\n",
    "    \n",
    "    # Average the scores for the individual images in the batch as described above\n",
    "    prediction_order = tf.math.reduce_mean(batch_scores_order, axis=0)\n",
    "    \n",
    "    # Route the current batch to the sub-module predcited by the order model and generate the\n",
    "    # predictions for the respective species category labels\n",
    "    batch_scores_species = species_models[tf.math.argmax(prediction_order)].predict(imgs)\n",
    "    \n",
    "    # Average the scores for the individual images in the batch as described above\n",
    "    prediction_species = tf.math.reduce_mean(batch_scores_species, axis=0)\n",
    "        \n",
    "    # Update custom metrics w/ the result for the current base image; as all images in one batch\n",
    "    # originate from the same base image (cf. above), the ground truth is hence identical as well.\n",
    "    \n",
    "    ground_truth_species = tf.math.argmax(ground_truths[0]).numpy()\n",
    "    ground_truth_phylum = ilsvrc2012_resolve_hypernym(ground_truth_species, ILSVRC2012_PHYLUM_LABEL_LEVEL, encoded=True)\n",
    "    ground_truth_class = ilsvrc2012_resolve_hypernym(ground_truth_species, ILSVRC2012_CLASS_LABEL_LEVEL, encoded=True)\n",
    "    ground_truth_order = ilsvrc2012_resolve_hypernym(ground_truth_species, ILSVRC2012_ORDER_LABEL_LEVEL, encoded=True)\n",
    "\n",
    "    cat_crossentropy_phylum.append(\n",
    "        -tf.math.reduce_sum(\n",
    "            tf.one_hot(ground_truth_phylum, ILSVRC2012_NUM_LABELS_PHYLUM_LAYER) * tf.math.log(prediction_phylum)))\n",
    "    cat_crossentropy_class.append(\n",
    "        -tf.math.reduce_sum(\n",
    "            tf.one_hot(ground_truth_class, ILSVRC2012_NUM_LABELS_CLASS_LAYER) * tf.math.log(prediction_class)))\n",
    "    cat_crossentropy_order.append(\n",
    "        -tf.math.reduce_sum(\n",
    "            tf.one_hot(ground_truth_order, ILSVRC2012_NUM_LABELS_ORDER_LAYER) * tf.math.log(prediction_order)))\n",
    "    cat_crossentropy_species.append(\n",
    "        -tf.math.reduce_sum(\n",
    "            tf.one_hot(ground_truth_species, ILSVRC2012_NUM_LABELS_SPECIES_LAYER) * tf.math.log(prediction_species)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the results\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_COMPNET + 'modeling_error_cat_crossentropy_phylum.data',\n",
    "    tf.io.serialize_tensor(cat_crossentropy_phylum))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_COMPNET + 'modeling_error_cat_crossentropy_class.data',\n",
    "    tf.io.serialize_tensor(cat_crossentropy_class))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_COMPNET + 'modeling_error_cat_crossentropy_order.data',\n",
    "    tf.io.serialize_tensor(cat_crossentropy_order))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_COMPNET + 'modeling_error_cat_crossentropy_species.data',\n",
    "    tf.io.serialize_tensor(cat_crossentropy_species))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the results\n",
    "\n",
    "cat_crossentropy_phylum = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_COMPNET + 'modeling_error_cat_crossentropy_phylum.data'),\n",
    "        tf.dtypes.float32)\n",
    "\n",
    "cat_crossentropy_class = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_COMPNET + 'modeling_error_cat_crossentropy_class.data'),\n",
    "        tf.dtypes.float32)\n",
    "\n",
    "cat_crossentropy_order = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_COMPNET + 'modeling_error_cat_crossentropy_order.data'),\n",
    "        tf.dtypes.float32)\n",
    "\n",
    "cat_crossentropy_species = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_COMPNET + 'modeling_error_cat_crossentropy_species.data'),\n",
    "        tf.dtypes.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(20, 10))\n",
    "\n",
    "ax.boxplot(\n",
    "    [cat_crossentropy_phylum,\n",
    "     cat_crossentropy_class,\n",
    "     cat_crossentropy_order,\n",
    "     cat_crossentropy_species],\n",
    "    sym='')\n",
    "\n",
    "ax.set_title('Developmet of categorical crossentropy across layers')\n",
    "ax.set_xlabel('Layer')\n",
    "ax.set_ylabel('Categorical crossentropy')\n",
    "ax.set_xticklabels(['phylum', 'class', 'order', 'species'])\n",
    "\n",
    "ax.grid(linestyle='--')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To evaluate how the composed model propagates data error across layers, we add artificial white\n",
    "# noise to the original images to model erroneous records.\n",
    "ilsvrc2012_test_data_error = process_and_augment(ilsvrc2012_test_raw, batch_size=10, synset_level=ILSVRC2012_SPECIES_LABEL_LEVEL, hypernym=None, is_train=False)\n",
    "ilsvrc2012_test_data_error = ilsvrc2012_test_data_error.unbatch().map(\n",
    "    lambda image, label: (\n",
    "        tf.dtypes.cast(\n",
    "            tf.math.maximum(\n",
    "                tf.math.minimum(\n",
    "                    tf.dtypes.cast(image, tf.dtypes.float32) + tf.random.normal((CROP_SIZE_H, CROP_SIZE_W, 3), mean=0, stddev=(RGB_MAX_VAL - RGB_MIN_VAL) / 20),\n",
    "                    RGB_MAX_VAL),\n",
    "                RGB_MIN_VAL),\n",
    "            tf.dtypes.uint8),\n",
    "        label),\n",
    "    num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize custom metrics to watch during the evaluation\n",
    "\n",
    "# Categorical crossentropies for each taxonomic category\n",
    "cat_crossentropy_phylum = []\n",
    "cat_crossentropy_class = []\n",
    "cat_crossentropy_order = []\n",
    "cat_crossentropy_species = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (imgs, ground_truths) in ilsvrc2012_test_data_error:\n",
    "    # Generate predictions for each image in the current batch\n",
    "    batch_scores_phylum = phylum_model.predict(imgs)\n",
    "    \n",
    "    # Since we constructed our test data set in a way that each image in one batch is an augmented\n",
    "    # version of the same base image, we can simply average the individual scores to get the final\n",
    "    # prediction for the respective base image in adherence to (Goodfellow et al., 2013) and\n",
    "    # (Krizhevsky et al., 2012).\n",
    "    prediction_phylum = tf.math.reduce_mean(batch_scores_phylum, axis=0)\n",
    "    \n",
    "    # Route the current batch to the sub-module predcited by the phylum model and generate the\n",
    "    # predictions for the respective class category labels\n",
    "    batch_scores_class = class_models[tf.math.argmax(prediction_phylum)].predict(imgs)\n",
    "    \n",
    "    # Average the scores for the individual images in the batch as described above\n",
    "    prediction_class = tf.math.reduce_mean(batch_scores_class, axis=0)\n",
    "    \n",
    "    # Route the current batch to the sub-module predcited by the class model and generate the\n",
    "    # predictions for the respective order category labels\n",
    "    batch_scores_order = order_models[tf.math.argmax(prediction_class)].predict(imgs)\n",
    "    \n",
    "    # Average the scores for the individual images in the batch as described above\n",
    "    prediction_order = tf.math.reduce_mean(batch_scores_order, axis=0)\n",
    "    \n",
    "    # Route the current batch to the sub-module predcited by the order model and generate the\n",
    "    # predictions for the respective species category labels\n",
    "    batch_scores_species = species_models[tf.math.argmax(prediction_order)].predict(imgs)\n",
    "    \n",
    "    # Average the scores for the individual images in the batch as described above\n",
    "    prediction_species = tf.math.reduce_mean(batch_scores_species, axis=0)\n",
    "        \n",
    "    # Update custom metrics w/ the result for the current base image; as all images in one batch\n",
    "    # originate from the same base image (cf. above), the ground truth is hence identical as well.\n",
    "    \n",
    "    ground_truth_species = tf.math.argmax(ground_truths[0]).numpy()\n",
    "    ground_truth_phylum = ilsvrc2012_resolve_hypernym(ground_truth_species, ILSVRC2012_PHYLUM_LABEL_LEVEL, encoded=True)\n",
    "    ground_truth_class = ilsvrc2012_resolve_hypernym(ground_truth_species, ILSVRC2012_CLASS_LABEL_LEVEL, encoded=True)\n",
    "    ground_truth_order = ilsvrc2012_resolve_hypernym(ground_truth_species, ILSVRC2012_ORDER_LABEL_LEVEL, encoded=True)\n",
    "\n",
    "    cat_crossentropy_phylum.append(\n",
    "        -tf.math.reduce_sum(\n",
    "            tf.one_hot(ground_truth_phylum, ILSVRC2012_NUM_LABELS_PHYLUM_LAYER) * tf.math.log(prediction_phylum)))\n",
    "    cat_crossentropy_class.append(\n",
    "        -tf.math.reduce_sum(\n",
    "            tf.one_hot(ground_truth_class, ILSVRC2012_NUM_LABELS_CLASS_LAYER) * tf.math.log(prediction_class)))\n",
    "    cat_crossentropy_order.append(\n",
    "        -tf.math.reduce_sum(\n",
    "            tf.one_hot(ground_truth_order, ILSVRC2012_NUM_LABELS_ORDER_LAYER) * tf.math.log(prediction_order)))\n",
    "    cat_crossentropy_species.append(\n",
    "        -tf.math.reduce_sum(\n",
    "            tf.one_hot(ground_truth_species, ILSVRC2012_NUM_LABELS_SPECIES_LAYER) * tf.math.log(prediction_species)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the results\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_COMPNET + 'data_error_cat_crossentropy_phylum.data',\n",
    "    tf.io.serialize_tensor(cat_crossentropy_phylum))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_COMPNET + 'data_error_cat_crossentropy_class.data',\n",
    "    tf.io.serialize_tensor(cat_crossentropy_class))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_COMPNET + 'data_error_cat_crossentropy_order.data',\n",
    "    tf.io.serialize_tensor(cat_crossentropy_order))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_COMPNET + 'data_error_cat_crossentropy_species.data',\n",
    "    tf.io.serialize_tensor(cat_crossentropy_species))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the results\n",
    "\n",
    "cat_crossentropy_phylum = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_COMPNET + 'data_error_cat_crossentropy_phylum.data'),\n",
    "        tf.dtypes.float32)\n",
    "\n",
    "cat_crossentropy_class = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_COMPNET + 'data_error_cat_crossentropy_class.data'),\n",
    "        tf.dtypes.float32)\n",
    "\n",
    "cat_crossentropy_order = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_COMPNET + 'data_error_cat_crossentropy_order.data'),\n",
    "        tf.dtypes.float32)\n",
    "\n",
    "cat_crossentropy_species = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_COMPNET + 'data_error_cat_crossentropy_species.data'),\n",
    "        tf.dtypes.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(20, 10))\n",
    "\n",
    "ax.boxplot(\n",
    "    [cat_crossentropy_phylum,\n",
    "     cat_crossentropy_class,\n",
    "     cat_crossentropy_order,\n",
    "     cat_crossentropy_species],\n",
    "    sym='')\n",
    "\n",
    "ax.set_title('Developmet of categorical crossentropy across layers')\n",
    "ax.set_xlabel('Layer')\n",
    "ax.set_ylabel('Categorical crossentropy')\n",
    "ax.set_xticklabels(['phylum', 'class', 'order', 'species'])\n",
    "\n",
    "ax.grid(linestyle='--')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Benchmark: VGG-19 (Simonyan et. al, 2015)\n",
    "<a id='benchmark'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a comparative benchmark, a (monolithic) VGG-19 Network as described in (Simonyan et. al, 2015) was trained on the basis of the same preprocessed dataset. Hyperparameters were chosen in accordance to the values reported in the original publication as far as possible; the rest was tuned experimentally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "<a id='benchmark_model'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg_model_from_template(input_shape=[224, 224, 3],\n",
    "                                num_classes=ILSVRC2012_NUM_LABELS_SPECIES_LAYER,\n",
    "                                num_conv_layers=16,\n",
    "                                num_conv_channels=[64, 64, 128, 128,\n",
    "                                                   256, 256, 256, 256,\n",
    "                                                   512, 512, 512, 512,\n",
    "                                                   512, 512, 512, 512],\n",
    "                                num_fc_layers=2,\n",
    "                                num_fc_neurons=4096)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Categorical Cross Entropy as loss function\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "# Define metrics to watch during training\n",
    "metrics = [tf.keras.metrics.CategoricalAccuracy(),\n",
    "           tf.keras.metrics.TopKCategoricalAccuracy(k=5),\n",
    "           tf.keras.metrics.CategoricalCrossentropy(),\n",
    "           tf.keras.metrics.AUC()]\n",
    "\n",
    "# Use Adam (Kingma et al., 2017) as optimizer during training\n",
    "# Annotation: We don't set `learning_rate` here as this is automatically handled by the\n",
    "# LearningRateScheduler (cf. callback section below).\n",
    "optimizer = tf.keras.optimizers.Adam(beta_1=0.9,\n",
    "                                     beta_2=0.999,\n",
    "                                     epsilon=1e-07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=loss, metrics=metrics, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively: Restore model from checkpoint\n",
    "# model = tf.keras.models.load_model(CKPT_DIR + 'vgg19')\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "<a id='benchmark_train'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ilsvrc2012_train = process_and_augment(ilsvrc2012_train_raw, batch_size=32, synset_level=ILSVRC2012_SPECIES_LABEL_LEVEL, hypernym=None, is_train=True, num_rnd_crops=5, shuffle_buffer_size=10000, num_epochs=1)\n",
    "ilsvrc2012_val = process_and_augment(ilsvrc2012_val_raw, batch_size=32, synset_level=ILSVRC2012_SPECIES_LABEL_LEVEL, hypernym=None, is_train=True, num_rnd_crops=5, shuffle_buffer_size=10000, num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EarlyStopping: Stop training early if no significant improvement in the monitored quantity is\n",
    "#     observed for at least `patience` epochs\n",
    "# LearningRateScheduler: Dynamically adapt the learning rate depending on the training epoch to\n",
    "#     facilitate accelerated learning during the first few epochs\n",
    "# ModelCheckpoint: Save the model after each epoch (if `save_best_only` is set to True, only keep\n",
    "#     the best model with regard to the monitored quantity)\n",
    "# TensorBoard: Enable TensorBoard visualization\n",
    "callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                              min_delta=0.01,\n",
    "                                              patience=3),\n",
    "             tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-02 if epoch < 3 else 1e-03),\n",
    "             tf.keras.callbacks.ModelCheckpoint(filepath=CKPT_DIR + 'vgg19',\n",
    "                                                monitor='val_loss',\n",
    "                                                verbose=False,\n",
    "                                                save_best_only=True),\n",
    "             tf.keras.callbacks.TensorBoard(log_dir=LOG_DIR,\n",
    "                                            histogram_freq=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=ilsvrc2012_train,\n",
    "          epochs=100,\n",
    "          verbose=True,\n",
    "          callbacks=callbacks,\n",
    "          validation_data=ilsvrc2012_val,\n",
    "          shuffle=True,\n",
    "          validation_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "<a id='benchmark_test'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform model evaluation adhering to the standard 10-crop procedure as described in (Goodfellow et al., 2013) and (Krizhevsky et al., 2012)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ilsvrc2012_test = process_and_augment(ilsvrc2012_test_raw, batch_size=10, synset_level=ILSVRC2012_SPECIES_LABEL_LEVEL, hypernym=None, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics to watch during the evaluation of the model on the test data set\n",
    "\n",
    "# Use the same metrics as for the training\n",
    "# test_metrics = metrics\n",
    "\n",
    "# Use different metrics than during the training\n",
    "test_metrics = [tf.keras.metrics.CategoricalAccuracy(name='CategoricalAccuracy'),\n",
    "                tf.keras.metrics.TopKCategoricalAccuracy(k=5, name='TopKCategoricalAccuracy'),\n",
    "                tf.keras.metrics.CategoricalCrossentropy(name='CategoricalCrossentropy'),\n",
    "                tf.keras.metrics.AUC(name='AUC')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset all metrics before starting the evaluation\n",
    "for metric in test_metrics:\n",
    "    metric.reset_states()\n",
    "    \n",
    "# Initialize additional custom metrics to watch during the evaluation\n",
    "\n",
    "# Overall label distribution (predicted and ground truth)\n",
    "dist_ground_truth = [0] * ILSVRC2012_NUM_LABELS_SPECIES_LAYER\n",
    "dist_predicted = [0] * ILSVRC2012_NUM_LABELS_SPECIES_LAYER\n",
    "\n",
    "# Predicted label distribution for each taxonomic category\n",
    "dist_predicted_phylum = [[0] * ILSVRC2012_NUM_LABELS_PHYLUM_LAYER for _ in range(ILSVRC2012_NUM_LABELS_PHYLUM_LAYER)]\n",
    "dist_predicted_class = [[0] * ILSVRC2012_NUM_LABELS_CLASS_LAYER for _ in range(ILSVRC2012_NUM_LABELS_CLASS_LAYER)]\n",
    "dist_predicted_order = [[0] * ILSVRC2012_NUM_LABELS_ORDER_LAYER for _ in range(ILSVRC2012_NUM_LABELS_ORDER_LAYER)]\n",
    "dist_predicted_species = [[0] * ILSVRC2012_NUM_LABELS_SPECIES_LAYER for _ in range(ILSVRC2012_NUM_LABELS_SPECIES_LAYER)]\n",
    "\n",
    "# Fine label distribution for each coarse category (predicted and ground truth)\n",
    "dist_ground_truth_phylum_class = [[0] * ILSVRC2012_NUM_LABELS_CLASS_LAYER for _ in range(ILSVRC2012_NUM_LABELS_PHYLUM_LAYER)]\n",
    "dist_predicted_phylum_class = [[0] * ILSVRC2012_NUM_LABELS_CLASS_LAYER for _ in range(ILSVRC2012_NUM_LABELS_PHYLUM_LAYER)]\n",
    "dist_ground_truth_phylum_order = [[0] * ILSVRC2012_NUM_LABELS_ORDER_LAYER for _ in range(ILSVRC2012_NUM_LABELS_PHYLUM_LAYER)]\n",
    "dist_predicted_phylum_order = [[0] * ILSVRC2012_NUM_LABELS_ORDER_LAYER for _ in range(ILSVRC2012_NUM_LABELS_PHYLUM_LAYER)]\n",
    "dist_ground_truth_phylum_species = [[0] * ILSVRC2012_NUM_LABELS_SPECIES_LAYER for _ in range(ILSVRC2012_NUM_LABELS_PHYLUM_LAYER)]\n",
    "dist_predicted_phylum_species = [[0] * ILSVRC2012_NUM_LABELS_SPECIES_LAYER for _ in range(ILSVRC2012_NUM_LABELS_PHYLUM_LAYER)]\n",
    "dist_ground_truth_class_order = [[0] * ILSVRC2012_NUM_LABELS_ORDER_LAYER for _ in range(ILSVRC2012_NUM_LABELS_CLASS_LAYER)]\n",
    "dist_predicted_class_order = [[0] * ILSVRC2012_NUM_LABELS_ORDER_LAYER for _ in range(ILSVRC2012_NUM_LABELS_CLASS_LAYER)]\n",
    "dist_ground_truth_class_species = [[0] * ILSVRC2012_NUM_LABELS_SPECIES_LAYER for _ in range(ILSVRC2012_NUM_LABELS_CLASS_LAYER)]\n",
    "dist_predicted_class_species = [[0] * ILSVRC2012_NUM_LABELS_SPECIES_LAYER for _ in range(ILSVRC2012_NUM_LABELS_CLASS_LAYER)]\n",
    "dist_ground_truth_order_species = [[0] * ILSVRC2012_NUM_LABELS_SPECIES_LAYER for _ in range(ILSVRC2012_NUM_LABELS_ORDER_LAYER)]\n",
    "dist_predicted_order_species = [[0] * ILSVRC2012_NUM_LABELS_SPECIES_LAYER for _ in range(ILSVRC2012_NUM_LABELS_ORDER_LAYER)]\n",
    "\n",
    "# Semantic distance between the predicted category and the ground truth in accordance to\n",
    "# (Fergus et al., 2010) \n",
    "semantic_distance = 0.0\n",
    "\n",
    "# Uncertainty metrics in accordance to (Ovadia et. al, 2019)\n",
    "confidence = []\n",
    "cat_acc = []\n",
    "neg_log_likelihood = []\n",
    "brier_score = []\n",
    "pred_entropy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (imgs, ground_truths) in ilsvrc2012_test:\n",
    "    # Generate predictions for each image in the current batch\n",
    "    batch_scores = model.predict(imgs)\n",
    "    \n",
    "    # Since we constructed our test data set in a way that each image in one batch is an augmented\n",
    "    # version of the same base image, we can simply average the individual scores to get the final\n",
    "    # prediction for the respective base image in adherence to (Goodfellow et al., 2013) and\n",
    "    # (Krizhevsky et al., 2012).\n",
    "    prediction = tf.math.reduce_mean(batch_scores, axis=0)\n",
    "    \n",
    "    # Update the metrics w/ the result for the current base image; as all images in one batch\n",
    "    # originate from the same base image (cf. above), the ground truth is hence identical as well.\n",
    "    # Annotation: The `tf.expand_dims` is a workaround for compatibility with\n",
    "    # `tf.keras.metrics.TopKCategoricalAccuracy` since the latter  does not accept one-dimensional\n",
    "    # inputs as of TensorFlow version v2.2.0-rc3.\n",
    "    for metric in test_metrics:\n",
    "        metric.update_state(tf.expand_dims(ground_truths[0], 0), tf.expand_dims(prediction, 0))\n",
    "        \n",
    "    # Update custom metrics w/ the result for the current base image; cf. above concerning the\n",
    "    # ground truth for each batch\n",
    "    \n",
    "    ground_truth = ground_truths[0]\n",
    "    ground_truth_species = tf.math.argmax(ground_truth).numpy()\n",
    "    ground_truth_species_decoded = ilsvrc2012_decode(ground_truth_species, ILSVRC2012_SPECIES_LABEL_LEVEL)\n",
    "    \n",
    "    ground_truth_phylum = ilsvrc2012_resolve_hypernym(ground_truth_species, ILSVRC2012_PHYLUM_LABEL_LEVEL, encoded=True)\n",
    "    ground_truth_class = ilsvrc2012_resolve_hypernym(ground_truth_species, ILSVRC2012_CLASS_LABEL_LEVEL, encoded=True)\n",
    "    ground_truth_order = ilsvrc2012_resolve_hypernym(ground_truth_species, ILSVRC2012_ORDER_LABEL_LEVEL, encoded=True)\n",
    "\n",
    "    prediction_species = tf.math.argmax(prediction).numpy()\n",
    "    prediction_species_decoded = ilsvrc2012_decode(prediction_species, ILSVRC2012_SPECIES_LABEL_LEVEL)\n",
    "    \n",
    "    prediction_phylum = ilsvrc2012_resolve_hypernym(prediction_species, ILSVRC2012_PHYLUM_LABEL_LEVEL, encoded=True)\n",
    "    prediction_class = ilsvrc2012_resolve_hypernym(prediction_species, ILSVRC2012_CLASS_LABEL_LEVEL, encoded=True)\n",
    "    prediction_order = ilsvrc2012_resolve_hypernym(prediction_species, ILSVRC2012_ORDER_LABEL_LEVEL, encoded=True)\n",
    "    \n",
    "    dist_ground_truth[ground_truth_species] += 1\n",
    "    dist_predicted[prediction_species] += 1\n",
    "\n",
    "    dist_predicted_phylum[ground_truth_phylum][prediction_phylum] += 1\n",
    "    dist_predicted_class[ground_truth_class][prediction_class] += 1\n",
    "    dist_predicted_order[ground_truth_order][prediction_order] += 1\n",
    "    dist_predicted_species[ground_truth_species][prediction_species] += 1\n",
    "\n",
    "    dist_ground_truth_phylum_class[ground_truth_phylum][prediction_class] += 1\n",
    "    dist_predicted_phylum_class[ground_truth_phylum][prediction_class] += 1\n",
    "    dist_ground_truth_phylum_order[ground_truth_phylum][prediction_order] += 1\n",
    "    dist_predicted_phylum_order[ground_truth_phylum][prediction_order] += 1\n",
    "    dist_ground_truth_phylum_species[ground_truth_phylum][prediction_species] += 1\n",
    "    dist_predicted_phylum_species[ground_truth_phylum][prediction_species] += 1\n",
    "    dist_ground_truth_class_order[ground_truth_class][prediction_order] += 1\n",
    "    dist_predicted_class_order[ground_truth_class][prediction_order] += 1\n",
    "    dist_ground_truth_class_species[ground_truth_class][prediction_species] += 1\n",
    "    dist_predicted_class_species[ground_truth_class][prediction_species] += 1\n",
    "    dist_ground_truth_order_species[ground_truth_order][prediction_species] += 1\n",
    "    dist_predicted_order_species[ground_truth_order][prediction_species] += 1\n",
    "    \n",
    "    semantic_distance += ILSVRC2012_SYNSET_MAP.semantic_distance(\n",
    "        ground_truth_species_decoded,\n",
    "        prediction_species_decoded\n",
    "    )\n",
    "\n",
    "    confidence.append(\n",
    "        prediction[prediction_species])\n",
    "        \n",
    "    cat_acc.append(\n",
    "        tf.dtypes.cast(tf.math.equal(ground_truth_species, prediction_species), tf.dtypes.float32))\n",
    "\n",
    "    neg_log_likelihood.append(\n",
    "        -tf.math.log(prediction[ground_truth_species]))\n",
    "\n",
    "    brier_score.append(\n",
    "        tf.math.reduce_sum((prediction - ground_truth) ** 2))\n",
    "\n",
    "    pred_entropy.append(\n",
    "        -tf.math.reduce_sum(tf.map_fn(lambda p: p * tf.math.log(p), prediction)))\n",
    "\n",
    "print('Benchmark')\n",
    "print()\n",
    "print('==================================================')\n",
    "print()\n",
    "print('Final results:')\n",
    "for metric in test_metrics:\n",
    "    print('{}: {}'.format(metric.name, metric.result().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the results\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_BENCHMARK + 'dist_ground_truth.data',\n",
    "    tf.io.serialize_tensor(dist_ground_truth))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_BENCHMARK + 'dist_predicted.data',\n",
    "    tf.io.serialize_tensor(dist_predicted))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_BENCHMARK + 'dist_predicted_phylum.data',\n",
    "    tf.io.serialize_tensor(dist_predicted_phylum))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_BENCHMARK + 'dist_predicted_class.data',\n",
    "    tf.io.serialize_tensor(dist_predicted_class))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_BENCHMARK + 'dist_predicted_order.data',\n",
    "    tf.io.serialize_tensor(dist_predicted_order))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_BENCHMARK + 'dist_predicted_species.data',\n",
    "    tf.io.serialize_tensor(dist_predicted_species))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_BENCHMARK + 'dist_ground_truth_phylum_class.data',\n",
    "    tf.io.serialize_tensor(dist_ground_truth_phylum_class))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_BENCHMARK + 'dist_predicted_phylum_class.data',\n",
    "    tf.io.serialize_tensor(dist_predicted_phylum_class))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_BENCHMARK + 'dist_ground_truth_phylum_order.data',\n",
    "    tf.io.serialize_tensor(dist_ground_truth_phylum_order))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_BENCHMARK + 'dist_predicted_phylum_order.data',\n",
    "    tf.io.serialize_tensor(dist_predicted_phylum_order))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_BENCHMARK + 'dist_ground_truth_phylum_species.data',\n",
    "    tf.io.serialize_tensor(dist_ground_truth_phylum_species))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_BENCHMARK + 'dist_predicted_phylum_species.data',\n",
    "    tf.io.serialize_tensor(dist_predicted_phylum_species))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_BENCHMARK + 'dist_ground_truth_class_order.data',\n",
    "    tf.io.serialize_tensor(dist_ground_truth_class_order))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_BENCHMARK + 'dist_predicted_class_order.data',\n",
    "    tf.io.serialize_tensor(dist_predicted_class_order))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_BENCHMARK + 'dist_ground_truth_class_species.data',\n",
    "    tf.io.serialize_tensor(dist_ground_truth_class_species))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_BENCHMARK + 'dist_predicted_class_species.data',\n",
    "    tf.io.serialize_tensor(dist_predicted_class_species))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_BENCHMARK + 'dist_ground_truth_order_species.data',\n",
    "    tf.io.serialize_tensor(dist_ground_truth_order_species))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_BENCHMARK + 'dist_predicted_order_species.data',\n",
    "    tf.io.serialize_tensor(dist_predicted_order_species))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_BENCHMARK + 'semantic_distance.data',\n",
    "    tf.io.serialize_tensor(semantic_distance))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_BENCHMARK + 'confidence.data',\n",
    "    tf.io.serialize_tensor(confidence))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_BENCHMARK + 'cat_acc.data',\n",
    "    tf.io.serialize_tensor(cat_acc))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_BENCHMARK + 'neg_log_likelihood.data',\n",
    "    tf.io.serialize_tensor(neg_log_likelihood))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_BENCHMARK + 'brier_score.data',\n",
    "    tf.io.serialize_tensor(brier_score))\n",
    "\n",
    "tf.io.write_file(\n",
    "    ILSVRC2012_RESULTS_DIR_BENCHMARK + 'pred_entropy.data',\n",
    "    tf.io.serialize_tensor(pred_entropy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the results\n",
    "\n",
    "dist_ground_truth = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_BENCHMARK + 'dist_ground_truth.data'),\n",
    "        tf.dtypes.int32)\n",
    "\n",
    "dist_predicted = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_BENCHMARK + 'dist_predicted.data'),\n",
    "        tf.dtypes.int32)\n",
    "\n",
    "dist_predicted_phylum = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_BENCHMARK + 'dist_predicted_phylum.data'),\n",
    "        tf.dtypes.int32)\n",
    "\n",
    "dist_predicted_class = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_BENCHMARK + 'dist_predicted_class.data'),\n",
    "        tf.dtypes.int32)\n",
    "\n",
    "dist_predicted_order = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_BENCHMARK + 'dist_predicted_order.data'),\n",
    "        tf.dtypes.int32)\n",
    "\n",
    "dist_predicted_species = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_BENCHMARK + 'dist_predicted_species.data'),\n",
    "        tf.dtypes.int32)\n",
    "\n",
    "dist_ground_truth_phylum_class = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_BENCHMARK + 'dist_ground_truth_phylum_class.data'),\n",
    "        tf.dtypes.int32)\n",
    "\n",
    "dist_predicted_phylum_class = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_BENCHMARK + 'dist_predicted_phylum_class.data'),\n",
    "        tf.dtypes.int32)\n",
    "\n",
    "dist_ground_truth_phylum_order = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_BENCHMARK + 'dist_ground_truth_phylum_order.data'),\n",
    "        tf.dtypes.int32)\n",
    "\n",
    "dist_predicted_phylum_order = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_BENCHMARK + 'dist_predicted_phylum_order.data'),\n",
    "        tf.dtypes.int32)\n",
    "\n",
    "dist_ground_truth_phylum_species = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_BENCHMARK + 'dist_ground_truth_phylum_species.data'),\n",
    "        tf.dtypes.int32)\n",
    "\n",
    "dist_predicted_phylum_species = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_BENCHMARK + 'dist_predicted_phylum_species.data'),\n",
    "        tf.dtypes.int32)\n",
    "\n",
    "dist_ground_truth_class_order = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_BENCHMARK + 'dist_ground_truth_class_order.data'),\n",
    "        tf.dtypes.int32)\n",
    "\n",
    "dist_predicted_class_order = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_BENCHMARK + 'dist_predicted_class_order.data'),\n",
    "        tf.dtypes.int32)\n",
    "\n",
    "dist_ground_truth_class_species = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_BENCHMARK + 'dist_ground_truth_class_species.data'),\n",
    "        tf.dtypes.int32)\n",
    "\n",
    "dist_predicted_class_species = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_BENCHMARK + 'dist_predicted_class_species.data'),\n",
    "        tf.dtypes.int32)\n",
    "\n",
    "dist_ground_truth_order_species = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_BENCHMARK + 'dist_ground_truth_order_species.data'),\n",
    "        tf.dtypes.int32)\n",
    "\n",
    "dist_predicted_order_species = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_BENCHMARK + 'dist_predicted_order_species.data'),\n",
    "        tf.dtypes.int32)\n",
    "\n",
    "semantic_distance = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_BENCHMARK + 'semantic_distance.data'),\n",
    "        tf.dtypes.float32)\n",
    "\n",
    "confidence = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_BENCHMARK + 'confidence.data'),\n",
    "        tf.dtypes.float32)\n",
    "\n",
    "cat_acc = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_BENCHMARK + 'cat_acc.data'),\n",
    "        tf.dtypes.float32)\n",
    "\n",
    "neg_log_likelihood = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_BENCHMARK + 'neg_log_likelihood.data'),\n",
    "        tf.dtypes.float32)\n",
    "\n",
    "brier_score = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_BENCHMARK + 'brier_score.data'),\n",
    "        tf.dtypes.float32)\n",
    "\n",
    "pred_entropy = tf.io.parse_tensor(\n",
    "    tf.io.read_file(\n",
    "        ILSVRC2012_RESULTS_DIR_BENCHMARK + 'pred_entropy.data'),\n",
    "        tf.dtypes.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 5))\n",
    "titles = ['Predicted', 'Ground Truth']\n",
    "\n",
    "for idx, dist in enumerate([dist_predicted, dist_ground_truth]):\n",
    "    # Normalize the distribution\n",
    "    dist = list(map(lambda entry: entry / sum(dist), dist)) \n",
    "                \n",
    "    # Plot the distribution\n",
    "    ax[idx].bar(range(1, len(dist) + 1), dist, width=1)\n",
    "    ax[idx].set_title(titles[idx])\n",
    "    ax[idx].set_xticks(range(0, ILSVRC2012_NUM_LABELS_SPECIES_LAYER, 25))\n",
    "    ax[idx].set_ylim([0, 0.033])\n",
    "    ax[idx].set_xlabel('Labels')\n",
    "    ax[idx].set_ylabel('Share')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=(20, 15))\n",
    "\n",
    "for label in range(ILSVRC2012_NUM_LABELS_PHYLUM_LAYER):\n",
    "    # Normalize the distribution\n",
    "    dist = list(map(\n",
    "        lambda entry: entry / sum(dist_predicted_phylum[label]), dist_predicted_phylum[label])) \n",
    "\n",
    "    # Plot the distribution\n",
    "    ax[label].bar(range(0, len(dist)), dist, width=1)\n",
    "    ax[label].set_title(\n",
    "        'Predicted Distribution for #{}'.format(ilsvrc2012_decode(label, ILSVRC2012_PHYLUM_LABEL_LEVEL))\n",
    "    )\n",
    "    ax[label].set_xticks(range(0, ILSVRC2012_NUM_LABELS_PHYLUM_LAYER, 1))\n",
    "    ax[label].set_xlabel('Labels')\n",
    "    ax[label].set_ylabel('Share')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(11, 1, figsize=(20, 165)\n",
    "\n",
    "for label in range(ILSVRC2012_NUM_LABELS_CLASS_LAYER):\n",
    "    # Normalize the distribution\n",
    "    dist = list(map(\n",
    "        lambda entry: entry / sum(dist_predicted_class[label]), dist_predicted_class[label])) \n",
    "\n",
    "    # Plot the distribution\n",
    "    ax[label].bar(range(0, len(dist)), dist, width=1)\n",
    "    ax[label].set_title(\n",
    "        'Predicted Distribution for #{}'.format(ilsvrc2012_decode(label, ILSVRC2012_CLASS_LABEL_LEVEL))\n",
    "    )\n",
    "    ax[label].set_xticks(range(0, ILSVRC2012_NUM_LABELS_CLASS_LAYER, 1))\n",
    "    ax[label].set_xlabel('Labels')\n",
    "    ax[label].set_ylabel('Share')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(12, 4, figsize=(20, 180))\n",
    "\n",
    "for label in range(ILSVRC2012_NUM_LABELS_ORDER_LAYER):\n",
    "    row = int(label / 4)\n",
    "    col = int(label % 4)\n",
    "    \n",
    "    # Normalize the distribution\n",
    "    dist = list(map(\n",
    "        lambda entry: entry / sum(dist_predicted_order[label]), dist_predicted_order[label])) \n",
    "\n",
    "    # Plot the distribution\n",
    "    ax[row][col].bar(range(0, len(dist)), dist, width=1)\n",
    "    ax[row][col].set_title(\n",
    "        'Predicted Distribution for #{}'.format(ilsvrc2012_decode(label, ILSVRC2012_ORDER_LABEL_LEVEL))\n",
    "    )\n",
    "    ax[row][col].set_xticks(range(0, ILSVRC2012_NUM_LABELS_ORDER_LAYER, 4))\n",
    "    ax[row][col].set_xlabel('Labels')\n",
    "    ax[row][col].set_ylabel('Share')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(95, 4, figsize=(20, 1425))\n",
    "\n",
    "for label in range(ILSVRC2012_NUM_LABELS_SPECIES_LAYER):\n",
    "    row = int(label / 4)\n",
    "    col = int(label % 4)\n",
    "    \n",
    "    # Normalize the distribution\n",
    "    dist = list(map(\n",
    "        lambda entry: entry / sum(dist_predicted_species[label]), dist_predicted_species[label])) \n",
    "\n",
    "    # Plot the distribution\n",
    "    ax[row][col].bar(range(0, len(dist)), dist, width=1)\n",
    "    ax[row][col].set_title(\n",
    "        'Predicted Distribution for #{}'.format(ilsvrc2012_decode(label, ILSVRC2012_SPECIES_LABEL_LEVEL))\n",
    "    )\n",
    "    ax[row][col].set_xticks(range(0, ILSVRC2012_NUM_LABELS_SPECIES_LAYER, 20))\n",
    "    ax[row][col].set_xlabel('Labels')\n",
    "    ax[row][col].set_ylabel('Share')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(20, 30))\n",
    "\n",
    "for label in range(ILSVRC2012_NUM_LABELS_PHYLUM_LAYER):\n",
    "    titles = ['Predicted Distribution for #{}'.format(ilsvrc2012_decode(label, ILSVRC2012_PHYLUM_LABEL_LEVEL)),\n",
    "          'Ground Truth Distribution for #{}'.format(ilsvrc2012_decode(label, ILSVRC2012_PHYLUM_LABEL_LEVEL))]\n",
    "\n",
    "    for idx, dist in enumerate([dist_predicted_phylum_class, dist_ground_truth_phylum_class]):\n",
    "        # Normalize the distribution\n",
    "        dist = list(map(lambda entry: entry / sum(dist[label]), dist[label])) \n",
    "                    \n",
    "        # Plot the distribution\n",
    "        ax[label][idx].bar(range(1, len(dist) + 1), dist, width=1)\n",
    "        ax[label][idx].set_title(titles[idx])\n",
    "        ax[label][idx].set_xticks(range(0, ILSVRC2012_NUM_LABELS_CLASS_LAYER, 1))\n",
    "        ax[label][idx].set_ylim([0, 0.33])\n",
    "        ax[label][idx].set_xlabel('Labels')\n",
    "        ax[label][idx].set_ylabel('Share')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(20, 30))\n",
    "\n",
    "for label in range(ILSVRC2012_NUM_LABELS_PHYLUM_LAYER):\n",
    "    titles = ['Predicted Distribution for #{}'.format(ilsvrc2012_decode(label, ILSVRC2012_PHYLUM_LABEL_LEVEL)),\n",
    "          'Ground Truth Distribution for #{}'.format(ilsvrc2012_decode(label, ILSVRC2012_PHYLUM_LABEL_LEVEL))]\n",
    "\n",
    "    for idx, dist in enumerate([dist_predicted_phylum_order, dist_ground_truth_phylum_order]):\n",
    "        # Normalize the distribution\n",
    "        dist = list(map(lambda entry: entry / sum(dist[label]), dist[label])) \n",
    "                    \n",
    "        # Plot the distribution\n",
    "        ax[label][idx].bar(range(1, len(dist) + 1), dist, width=1)\n",
    "        ax[label][idx].set_title(titles[idx])\n",
    "        ax[label][idx].set_xticks(range(0, ILSVRC2012_NUM_LABELS_ORDER_LAYER, 4))\n",
    "        ax[label][idx].set_ylim([0, 0.01])\n",
    "        ax[label][idx].set_xlabel('Labels')\n",
    "        ax[label][idx].set_ylabel('Share')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(20, 30))\n",
    "\n",
    "for label in range(ILSVRC2012_NUM_LABELS_PHYLUM_LAYER):\n",
    "    titles = ['Predicted Distribution for #{}'.format(ilsvrc2012_decode(label, ILSVRC2012_PHYLUM_LABEL_LEVEL)),\n",
    "          'Ground Truth Distribution for #{}'.format(ilsvrc2012_decode(label, ILSVRC2012_PHYLUM_LABEL_LEVEL))]\n",
    "\n",
    "    for idx, dist in enumerate([dist_predicted_phylum_species, dist_ground_truth_phylum_species]):\n",
    "        # Normalize the distribution\n",
    "        dist = list(map(lambda entry: entry / sum(dist[label]), dist[label])) \n",
    "                    \n",
    "        # Plot the distribution\n",
    "        ax[label][idx].bar(range(1, len(dist) + 1), dist, width=1)\n",
    "        ax[label][idx].set_title(titles[idx])\n",
    "        ax[label][idx].set_xticks(range(0, ILSVRC2012_NUM_LABELS_SPECIES_LAYER, 20))\n",
    "        ax[label][idx].set_ylim([0, 0.033])\n",
    "        ax[label][idx].set_xlabel('Labels')\n",
    "        ax[label][idx].set_ylabel('Share')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(11, 2, figsize=(20, 165))\n",
    "\n",
    "for label in range(ILSVRC2012_NUM_LABELS_CLASS_LAYER):\n",
    "    titles = ['Predicted Distribution for #{}'.format(ilsvrc2012_decode(label, ILSVRC2012_CLASS_LABEL_LEVEL)),\n",
    "          'Ground Truth Distribution for #{}'.format(ilsvrc2012_decode(label, ILSVRC2012_CLASS_LABEL_LEVEL))]\n",
    "\n",
    "    for idx, dist in enumerate([dist_predicted_class_order, dist_ground_truth_class_order]):\n",
    "        # Normalize the distribution\n",
    "        dist = list(map(lambda entry: entry / sum(dist[label]), dist[label])) \n",
    "                    \n",
    "        # Plot the distribution\n",
    "        ax[label][idx].bar(range(1, len(dist) + 1), dist, width=1)\n",
    "        ax[label][idx].set_title(titles[idx])\n",
    "        ax[label][idx].set_xticks(range(0, ILSVRC2012_NUM_LABELS_ORDER_LAYER, 4))\n",
    "        ax[label][idx].set_ylim([0, 0.01])\n",
    "        ax[label][idx].set_xlabel('Labels')\n",
    "        ax[label][idx].set_ylabel('Share')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(11, 2, figsize=(20, 165))\n",
    "\n",
    "for label in range(ILSVRC2012_NUM_LABELS_CLASS_LAYER):\n",
    "    titles = ['Predicted Distribution for #{}'.format(ilsvrc2012_decode(label, ILSVRC2012_CLASS_LABEL_LEVEL)),\n",
    "          'Ground Truth Distribution for #{}'.format(ilsvrc2012_decode(label, ILSVRC2012_CLASS_LABEL_LEVEL))]\n",
    "\n",
    "    for idx, dist in enumerate([dist_predicted_class_species, dist_ground_truth_class_species]):\n",
    "        # Normalize the distribution\n",
    "        dist = list(map(lambda entry: entry / sum(dist[label]), dist[label])) \n",
    "                    \n",
    "        # Plot the distribution\n",
    "        ax[label][idx].bar(range(1, len(dist) + 1), dist, width=1)\n",
    "        ax[label][idx].set_title(titles[idx])\n",
    "        ax[label][idx].set_xticks(range(0, ILSVRC2012_NUM_LABELS_SPECIES_LAYER, 20))\n",
    "        ax[label][idx].set_ylim([0, 0.033])\n",
    "        ax[label][idx].set_xlabel('Labels')\n",
    "        ax[label][idx].set_ylabel('Share')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(47, 2, figsize=(20, 40))\n",
    "\n",
    "for label in range(ILSVRC2012_NUM_LABELS_ORDER_LAYER):\n",
    "    titles = ['Predicted Distribution for #{}'.format(ilsvrc2012_decode(label, ILSVRC2012_ORDER_LABEL_LEVEL)),\n",
    "          'Ground Truth Distribution for #{}'.format(ilsvrc2012_decode(label, ILSVRC2012_ORDER_LABEL_LEVEL))]\n",
    "\n",
    "    for idx, dist in enumerate([dist_predicted_order_species, dist_ground_truth_order_species]):\n",
    "        # Normalize the distribution\n",
    "        dist = list(map(lambda entry: entry / sum(dist[label]), dist[label])) \n",
    "                    \n",
    "        # Plot the distribution\n",
    "        ax[label][idx].bar(range(1, len(dist) + 1), dist, width=1)\n",
    "        ax[label][idx].set_title(titles[idx])\n",
    "        ax[label][idx].set_xticks(range(0, ILSVRC2012_NUM_LABELS_SPECIES_LAYER, 20))\n",
    "        ax[label][idx].set_ylim([0, 0.033])\n",
    "        ax[label][idx].set_xlabel('Labels')\n",
    "        ax[label][idx].set_ylabel('Share')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(20, 10))\n",
    "\n",
    "ax.boxplot(cat_acc, sym='')\n",
    "\n",
    "ax.set_title('Categorical accuracy over varying corruption severities')\n",
    "ax.set_ylabel('Accuracy')\n",
    "\n",
    "ax.grid(linestyle='--')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(20, 10))\n",
    "\n",
    "ax.boxplot(brier_score, sym='')\n",
    "\n",
    "ax.set_title('Brier Score over varying corruption severities')\n",
    "ax.set_ylabel('Brier Score')\n",
    "\n",
    "ax.grid(linestyle='--')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(20, 10))\n",
    "\n",
    "ax.hist(confidence[idx], bins=10000, cumulative=-1, histtype='step')\n",
    "ax.set_title('Confidence')\n",
    "ax.set_xlabel('Confidence ' + r'$\\tau$')\n",
    "ax.set_ylabel('Number examples ' + r'$P(x) > \\tau$')\n",
    "#ax.set_xlim([0.002, 1.0])\n",
    "\n",
    "ax.grid(linestyle='--')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(20, 10))\n",
    "\n",
    "ax.hist(neg_log_likelihood[idx], bins=10000, histtype='step')\n",
    "ax.set_title('Negative log likelihood')\n",
    "ax.set_xlabel('Likelihood ' + r'$l$')\n",
    "ax.set_ylabel('Number examples ' + r'$L(x) > l$')\n",
    "#ax.set_xlim([0.202, 1.0])\n",
    "\n",
    "ax.grid(linestyle='--')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(20, 10))\n",
    "\n",
    "ax.hist(pred_entropy[idx], bins=10000, cumulative=-1, histtype='step')\n",
    "ax.set_title('Predictive entropy')\n",
    "ax.set_xlabel('Entropy (Nats)' + r'$h$')\n",
    "ax.set_ylabel('Number examples ' + r'$H(x) > h$')\n",
    "#ax.set_xlim([0.0, 2.5])\n",
    "\n",
    "ax.grid(linestyle='--')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(20, 10))\n",
    "\n",
    "ax.plot(\n",
    "    [val for val in sorted(confidence[idx])],\n",
    "    [val for _, val in sorted(zip(confidence[idx], cat_acc[idx]))])\n",
    "ax.set_title('Confidence vs accuracy')\n",
    "ax.set_xlabel('Confidence ' + r'$\\tau$')\n",
    "ax.set_ylabel('Categorical accuracy on examples ' + r'$P(x) > \\tau$')\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "\n",
    "ax.grid(linestyle='--')\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp_net (Python 3.6.9)",
   "language": "python",
   "name": "comp_net"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
